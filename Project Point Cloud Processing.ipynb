{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Sally Sisi Qu\n",
    "### ID: 169001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this project, you will be asked to implement [PointNet](https://arxiv.org/abs/1612.00593) architecture and train a classification network (left) and a segmentation network (middle).\n",
    "![title](img/cls_sem.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Points\n",
    "* Task 1.1 - 5\n",
    "* Task 1.2 - 5\n",
    "* Task 2.1 - 10\n",
    "* Task 2.2 - 5\n",
    "* Task 2.3 - 5\n",
    "* Task 2.4 - 5\n",
    "* Task 2.5 - 5\n",
    "* Task 2.6 - 10\n",
    "* Task 2.7 - 5\n",
    "* Task 2.8 - 10\n",
    "* Task 2.9 - 10\n",
    "* Task 2.10 - 5 \n",
    "* Task 2.11 - 5\n",
    "* Task 2.12 - 5\n",
    "* Task 2.13 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import dataset # custom dataset for ModelNet10 and ShapeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we write the point cloud as $X\\in\\mathbb{R}^{N\\times 3}$. While in programming, we use `B x 3 x N` layout, where `B` is the batch-size and `N` is the number of points in a single point cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Jitter the position of each points by a zero mean Gaussian\n",
    "For input $X\\in\\mathbb{R}^{N\\times 3}$, we transform $X$ by $X \\leftarrow X + \\mathcal{N}(0, \\sigma^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomJitter(object):\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        ## hint: useful function `torch.randn` and `torch.randn_like`\n",
    "        ## TASK 1.1\n",
    "        ## This function takes as input a point cloud of layout `3 x N`, \n",
    "        ## and output the jittered point cloud of layout `3 x N`.\n",
    "        data += torch.randn_like(data).normal_(0, self.sigma)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0735,  0.0092, -0.4380,  3.6914, -0.6869,  0.6769, -0.7465,  0.2815,\n",
      "          0.1756, -1.5641],\n",
      "        [-0.2080, -0.2250,  0.3701, -0.6151, -0.3259,  0.7582, -1.2463, -2.5635,\n",
      "         -2.3841, -1.8180],\n",
      "        [-0.9242, -3.9937,  2.8220, -2.9388, -1.0028, -0.1808,  0.1078,  0.9008,\n",
      "          3.0704, -2.7517]])\n"
     ]
    }
   ],
   "source": [
    "## random generate data and test your transform here\n",
    "a = torch.randn(3,10)\n",
    "b = torch.randn_like(a).normal_(0, 2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Rotate the object along the z-axis randomly\n",
    "For input $X\\in\\mathbb{R}^{N\\times 3}$, we rotate all points along z-axis (up-axis) by a degree $\\theta$.\n",
    "\n",
    "\n",
    "Suppose $T$ is the transformation matrix,\n",
    "$$X\\leftarrow XT,$$\n",
    "where $$T=\\begin{bmatrix}\\cos\\theta & \\sin\\theta & 0 \\\\ -\\sin\\theta & \\cos\\theta & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomZRotate(object):\n",
    "    def __init__(self, degrees):\n",
    "        ## here `self.degrees` is a tuple (0, 360) which defines the range of degree\n",
    "        self.degrees = degrees\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        ## TASK 1.2\n",
    "        ## This function takes as input a point cloud of layout `3 x N`, \n",
    "        ## and output the rotated point cloud of layout `3 x N`.\n",
    "        ##\n",
    "        ## The rotation is along z-axis, and the degree is uniformly distributed\n",
    "        ## between [0, 360]\n",
    "        ##\n",
    "        ## hint: useful function `torch.randn`ï¼Œ `torch.randn_like` and `torch.matmul`\n",
    "        ##\n",
    "        ## Notice:   \n",
    "        ## Different from its math notation `N x 3`, the input has size of `3 x N`\n",
    "        # torch.rand \"(0,1)\"\n",
    "        theta = torch.rand(1) * (self.degrees[1] - self.degrees[0]) + self.degrees[0]\n",
    "        sin = torch.sin(theta/360 * 2 * np.pi)\n",
    "        cos = torch.cos(theta)\n",
    "        mat = torch.tensor([[cos, sin, 0],\n",
    "                          [-sin, cos, 0],\n",
    "                          [0,0,1]])\n",
    "        data = torch.matmul(mat, data)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4911, -0.7101,  0.3581, -0.5455,  1.4950, -1.5668, -0.6998, -2.6751,\n",
      "          1.1887,  1.1018],\n",
      "        [-0.4432, -0.7006, -0.0878, -0.3871, -2.4042, -0.1400, -0.0682, -0.9424,\n",
      "         -0.5377,  0.0166],\n",
      "        [ 0.3169,  2.2118, -0.7978,  1.3652, -0.1872, -0.6404,  0.1839, -0.8140,\n",
      "          0.9096,  1.0974]])\n"
     ]
    }
   ],
   "source": [
    "## random generate data and test your transform here\n",
    "a = torch.randn(3,10)\n",
    "thetat = torch.rand(1) * 360 + 0\n",
    "sint = torch.sin(thetat)\n",
    "cost = torch.cos(thetat)\n",
    "matt = torch.tensor([[cost, sint, 0],[-sint, cost, 0],[0,0,1]])\n",
    "datat = torch.matmul(matt, a)\n",
    "print(datat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Load dataset ModelNet10 for Point Cloud Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelNet10\n",
    "By loading this dataset, we have data of shape `B x 3 x N` and label of shape `B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It may taske some time to download and pre-process the dataset.\n",
    "train_transform = Compose([RandomZRotate((0, 360)), RandomJitter(0.02)])\n",
    "train_cls_dataset = dataset.ModelNet(root='./ModelNet10', transform=train_transform, train=True)\n",
    "test_cls_dataset = dataset.ModelNet(root='./ModelNet10', train=False)\n",
    "train_cls_loader = data.DataLoader(\n",
    "    train_cls_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "test_cls_loader = data.DataLoader(\n",
    "    test_cls_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(train_cls_dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShapeNet\n",
    "By loading this dataset, we have data of shape `B x 3 x N` and target of shape `B x N`.\n",
    "\n",
    "Here is the list of categories:\n",
    "['Airplane', 'Bag', 'Cap', 'Car', 'Chair', 'Earphone', 'Guitar', 'Knife', 'Lamp', 'Laptop', 'Motorbike', 'Mug', 'Pistol', 'Rocket', 'Skateboard', 'Table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here as an example, we choose the cateogry 'Airplane'\n",
    "category = 'Airplane'\n",
    "train_seg_dataset = dataset.ShapeNet(root='./ShapeNet', category=category, train=True)\n",
    "test_seg_dataset = dataset.ShapeNet(root='./ShapeNet', category=category, train=False)\n",
    "train_seg_loader = data.DataLoader(\n",
    "    train_seg_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "test_seg_loader = data.DataLoader(\n",
    "    test_seg_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(train_seg_dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 PointNet Architecture (Read Section 4.2 and Appendix C)\n",
    "In this section, you will be asked to implement classification and segmentation step by step.\n",
    "![pointnet](img/pointnet.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Joint Alignment Network \n",
    "This mini-network takes as input matrix of size $N \\times K$, and outputs a transformation matrix of size $K \\times K$. \n",
    "\n",
    "In programming, the input size of this module is `B x K x N` and output size is `B x K x K`.\n",
    "\n",
    "For the shared MLP, use structure like this `(FC(64), BN, ReLU, FC(128), BN, ReLU, FC(1024), BN, ReLU)`.\n",
    "\n",
    "For the MLP after global max pooling, use structure like this `(FC(512), BN, ReLU, FC(256), BN, ReLU, FC(K*K)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict as OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformation(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super(Transformation, self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        ## TASK 2.1\n",
    "        \n",
    "        ## define your network layers here\n",
    "        ## shared mlp\n",
    "        ## input size: B x K x N\n",
    "        ## output size: B x 1024 x N\n",
    "        ## hint: you may want to use `nn.Conv1d` here. Why?\n",
    "        # nn.Conv1d for 3-dimensional data\n",
    "        self.shared_mlp = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv1d(k,64,1)),\n",
    "          ('bn1', nn.BatchNorm1d(64)),  \n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv1d(64,128,1)),\n",
    "          ('bn2', nn.BatchNorm1d(128)),  \n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('conv3', nn.Conv1d(128,1024,1)),\n",
    "          ('bn3', nn.BatchNorm1d(1024)),  \n",
    "          ('relu3', nn.ReLU())\n",
    "        ]))\n",
    "        \n",
    "        ## define your network layers here\n",
    "        ## mlp\n",
    "        ## input size: B x 1024\n",
    "        ## output size: B x (K*K)\n",
    "        self.mlp = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(1024,512,1)),\n",
    "          ('bn1', nn.BatchNorm1d(512)),  \n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(512,256,1)),\n",
    "          ('bn2', nn.BatchNorm1d(256)),  \n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('fc3', nn.Linear(256,k*k,1)),            \n",
    "        ]))\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, K, N = x.shape # batch-size, dim, number of points\n",
    "        ## TASK 2.1\n",
    "\n",
    "        ## forward of shared mlp\n",
    "        # input - B x K x N\n",
    "        # output - B x 1024 x N\n",
    "        x = self.shared_mlp(x)\n",
    "        \n",
    "        ## global max pooling\n",
    "        # input - B x 1024 x N\n",
    "        # output - B x 1024\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        \n",
    "        ## mlp\n",
    "        # input - B x 1024\n",
    "        # output - B x (K*K)\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        ## reshape the transformation matrix to B x K x K\n",
    "        identity = torch.eye(self.k, device=x.device)\n",
    "        x = x.view(B, self.k, self.k) + identity[None]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 100]             256\n",
      "       BatchNorm1d-2              [-1, 64, 100]             128\n",
      "              ReLU-3              [-1, 64, 100]               0\n",
      "            Conv1d-4             [-1, 128, 100]           8,320\n",
      "       BatchNorm1d-5             [-1, 128, 100]             256\n",
      "              ReLU-6             [-1, 128, 100]               0\n",
      "            Conv1d-7            [-1, 1024, 100]         132,096\n",
      "       BatchNorm1d-8            [-1, 1024, 100]           2,048\n",
      "              ReLU-9            [-1, 1024, 100]               0\n",
      "           Linear-10                  [-1, 512]         524,800\n",
      "      BatchNorm1d-11                  [-1, 512]           1,024\n",
      "             ReLU-12                  [-1, 512]               0\n",
      "           Linear-13                  [-1, 256]         131,328\n",
      "      BatchNorm1d-14                  [-1, 256]             512\n",
      "             ReLU-15                  [-1, 256]               0\n",
      "           Linear-16                    [-1, 9]           2,313\n",
      "================================================================\n",
      "Total params: 803,081\n",
      "Trainable params: 803,081\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.80\n",
      "Params size (MB): 3.06\n",
      "Estimated Total Size (MB): 5.87\n",
      "----------------------------------------------------------------\n",
      "Transformation(\n",
      "  (shared_mlp): Sequential(\n",
      "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "T = Transformation().cuda()\n",
    "summary(T, input_size= (3,  100))\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9902,  0.1703, -0.6293],\n",
       "         [-0.3769,  1.6853,  0.3421],\n",
       "         [-0.0086,  1.0022,  1.8099]],\n",
       "\n",
       "        [[ 1.8576, -0.4449,  0.7118],\n",
       "         [-0.1011,  1.6754, -0.1013],\n",
       "         [ 0.2772,  0.3234,  1.2093]],\n",
       "\n",
       "        [[ 1.3320, -0.4658, -0.6449],\n",
       "         [-0.0248,  1.5130, -0.0843],\n",
       "         [-1.0352, -0.3630,  0.7296]],\n",
       "\n",
       "        [[ 1.8176, -0.8262, -0.2564],\n",
       "         [ 0.1584,  1.4714,  0.3585],\n",
       "         [-0.3193,  0.6245,  0.9849]],\n",
       "\n",
       "        [[ 1.1638, -0.3135,  0.0896],\n",
       "         [-0.2103,  0.9192, -0.0642],\n",
       "         [ 0.1120, -0.3275,  0.8746]],\n",
       "\n",
       "        [[ 0.7147, -0.2876, -0.1989],\n",
       "         [ 0.3344,  1.4045, -0.3549],\n",
       "         [ 0.0133,  0.1862,  1.3974]],\n",
       "\n",
       "        [[ 1.9801,  0.5717,  0.1130],\n",
       "         [-0.3813,  1.4358,  0.2630],\n",
       "         [-0.4527,  0.8670,  1.1567]],\n",
       "\n",
       "        [[ 1.3908, -0.1667,  1.2239],\n",
       "         [ 0.4074,  1.3785, -0.1214],\n",
       "         [ 0.1438,  0.6716,  0.8487]],\n",
       "\n",
       "        [[ 1.3346, -0.4561, -0.0301],\n",
       "         [-0.2884,  1.6216, -0.1106],\n",
       "         [-0.0162,  0.3022,  0.9225]],\n",
       "\n",
       "        [[ 1.1273, -0.0224,  0.2691],\n",
       "         [ 0.6713,  0.8981, -0.2018],\n",
       "         [-0.7100, -0.6845,  1.2401]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## random generate data and test this network\n",
    "d = torch.randn(10,3,100).cuda()\n",
    "T(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Regularization Loss\n",
    "$$L_{reg}=\\|I-TT^\\intercal\\|^2_F$$\n",
    "\n",
    "The output of `Transformation` network is of size `B x K x K`. The module `OrthoLoss` has no trainable parameters, only computes this norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthoLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OrthoLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## hint: useful function `torch.bmm` and `torch.matmul`\n",
    "        \n",
    "        ## TASK 2.2\n",
    "        ## compute the matrix product\n",
    "        prod = torch.bmm(x, x.transpose(1,2))\n",
    "\n",
    "        norm = torch.norm(prod - torch.eye(x.shape[1], device=x.device)[None], dim=(1,2))\n",
    "        return norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46.0790)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## random generate data and test this network\n",
    "a = torch.randn(3, 10, 10)\n",
    "ortho = OrthoLoss()\n",
    "ortho(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Feature Network\n",
    "In this subsection, you will be asked to implement the feature network (the top branch).\n",
    "\n",
    "Local features are a matrix of size `B x 64 x N`, which will be used in the segmentation task.\n",
    "\n",
    "Global features are a matrix of size `B x 1024`, which will be used in the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature(nn.Module):\n",
    "    def __init__(self, alignment=False):\n",
    "        super(Feature, self).__init__()\n",
    "        \n",
    "        self.alignment = alignment\n",
    "        \n",
    "        ## `input_transform` calculates the input transform matrix of size `3 x 3`\n",
    "        if self.alignment:\n",
    "            self.input_transform = Transformation(3)\n",
    "        \n",
    "        ## TASK 2.3\n",
    "        ## define your network layers here\n",
    "        ## local feature\n",
    "        ## shared mlp\n",
    "        ## input size: B x 3 x N\n",
    "        ## output size: B x 64 x N\n",
    "        ## hint: you may want to use `nn.Conv1d` here.\n",
    "        self.local_sharedmlp = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv1d(3,64,1)),\n",
    "          ('bn1', nn.BatchNorm1d(64)),  \n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv1d(64,64,1)),\n",
    "          ('bn2', nn.BatchNorm1d(64)),  \n",
    "          ('relu2', nn.ReLU()),\n",
    "        ]))        \n",
    "        \n",
    "        ## `feature_transform` calculates the feature transform matrix of size `64 x 64`\n",
    "        if self.alignment:\n",
    "            self.feature_transform = Transformation(64)\n",
    "        \n",
    "        ## TASK 2.4\n",
    "        ## define your network layers here\n",
    "        ## global feature\n",
    "        ## shared mlp\n",
    "        ## input size: B x 64 x N\n",
    "        self.global_sharedmlp = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv1d(64,64,1)),\n",
    "          ('bn1', nn.BatchNorm1d(64)),  \n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv1d(64,128,1)),\n",
    "          ('bn2', nn.BatchNorm1d(128)),  \n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('conv3', nn.Conv1d(128,1024,1)),\n",
    "          ('bn3', nn.BatchNorm1d(1024)),  \n",
    "        ]))\n",
    "  \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ## apply the input transform\n",
    "        if self.alignment:\n",
    "            transform = self.input_transform(x)\n",
    "            ## TASK 2.5\n",
    "            ## apply the input transform\n",
    "            x = torch.bmm(transform, x)\n",
    "\n",
    "        ## TASK 2.3\n",
    "        ## forward of shared mlp\n",
    "        # input - B x K x N\n",
    "        # output - B x 64 x N\n",
    "        x = self.local_sharedmlp(x)\n",
    "        \n",
    "        if self.alignment:\n",
    "            transform = self.feature_transform(x)\n",
    "            ## TASK 2.5\n",
    "            ## apply the feature transform\n",
    "            x = torch.bmm(transform, x)\n",
    "        else:\n",
    "            ## do not modify this line\n",
    "            transform = None\n",
    "        \n",
    "        local_feature = x\n",
    "        \n",
    "        ## TASK 2.4\n",
    "        ## forward of shared mlp\n",
    "        # input - B x 64 x N\n",
    "        # output - B x 1024 x N\n",
    "        x = self.global_sharedmlp(x)\n",
    "        \n",
    "        ## TASK 2.4\n",
    "        ## global max pooling\n",
    "        # input - B x 1024 x N\n",
    "        # output - B x 1024\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        \n",
    "        global_feature = x\n",
    "        \n",
    "        ## summary:\n",
    "        ## global_feature: B x 1024\n",
    "        ## local_feature: B x 64 x N\n",
    "        ## transform: B x K x K\n",
    "        return global_feature, local_feature, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 100]             256\n",
      "       BatchNorm1d-2              [-1, 64, 100]             128\n",
      "              ReLU-3              [-1, 64, 100]               0\n",
      "            Conv1d-4              [-1, 64, 100]           4,160\n",
      "       BatchNorm1d-5              [-1, 64, 100]             128\n",
      "              ReLU-6              [-1, 64, 100]               0\n",
      "            Conv1d-7              [-1, 64, 100]           4,160\n",
      "       BatchNorm1d-8              [-1, 64, 100]             128\n",
      "              ReLU-9              [-1, 64, 100]               0\n",
      "           Conv1d-10             [-1, 128, 100]           8,320\n",
      "      BatchNorm1d-11             [-1, 128, 100]             256\n",
      "             ReLU-12             [-1, 128, 100]               0\n",
      "           Conv1d-13            [-1, 1024, 100]         132,096\n",
      "      BatchNorm1d-14            [-1, 1024, 100]           2,048\n",
      "================================================================\n",
      "Total params: 151,680\n",
      "Trainable params: 151,680\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.29\n",
      "Params size (MB): 0.58\n",
      "Estimated Total Size (MB): 2.87\n",
      "----------------------------------------------------------------\n",
      "<module 'torch.nn.functional' from '/home/qus/anaconda3/envs/py37tch13/lib/python3.7/site-packages/torch/nn/functional.py'>\n"
     ]
    }
   ],
   "source": [
    "Ft = Feature().cuda()\n",
    "summary(Ft, input_size= (3,  100))\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "## random generate data and test this network\n",
    "d = torch.randn(10,3,100).cuda()\n",
    "test = Ft(d)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Classification Network\n",
    "In this network, you will use the global features generated by the `Feature` network defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self, num_classes, alignment=False):\n",
    "        super(Classification, self).__init__()\n",
    "                \n",
    "        self.feature = Feature(alignment=alignment)\n",
    "        \n",
    "        ## TASK 2.6\n",
    "        ## define your network layers here\n",
    "        ## mlp\n",
    "        ## input size: B x 1024\n",
    "        ## output size: B x num_classes\n",
    "        self.cls_layers = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(1024,512,1)),\n",
    "          ('bn1', nn.BatchNorm1d(512)),  \n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(512,256,1)),\n",
    "          ('dp', nn.Dropout(p = 0.3)),\n",
    "          ('bn2', nn.BatchNorm1d(256)),  \n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('fc3', nn.Linear(256,num_classes,1))\n",
    "        ]))       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is the global feature matrix\n",
    "        # here we don't use local feature matrix\n",
    "        x, _, trans = self.feature(x)\n",
    "        \n",
    "        ## TASK 2.6\n",
    "        ## forward of mlp\n",
    "        # input - B x 1024\n",
    "        # output - B x num_classes        \n",
    "        x = self.cls_layers(x)\n",
    "        \n",
    "        ## x: B x num_classes\n",
    "        ## trans: B x K x K\n",
    "        return x, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification(\n",
      "  (feature): Feature(\n",
      "    (input_transform): Transformation(\n",
      "      (shared_mlp): Sequential(\n",
      "        (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU()\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (local_sharedmlp): Sequential(\n",
      "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (feature_transform): Transformation(\n",
      "      (shared_mlp): Sequential(\n",
      "        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU()\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (global_sharedmlp): Sequential(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (cls_layers): Sequential(\n",
      "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (dp): Dropout(p=0.3, inplace=False)\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "C = Classification(10, True).cuda()\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0149, -0.3381, -0.4680,  0.2336, -0.6388, -0.6762,  0.4531, -0.4477,\n",
      "          0.4952,  0.2996],\n",
      "        [ 0.6362, -0.4092,  0.3624,  0.5588, -0.0513, -0.3604, -0.1470, -0.7514,\n",
      "          0.1698, -0.3216],\n",
      "        [ 0.0385,  0.2391, -0.2328, -0.0151, -1.0534, -0.8248, -0.1934, -0.1495,\n",
      "          0.1572, -0.6947],\n",
      "        [ 0.5139, -0.3029, -0.5252,  0.4859, -0.1303, -0.4121, -0.0935, -0.2230,\n",
      "          0.5934, -0.4780],\n",
      "        [ 0.6860, -0.1916, -0.3970,  0.1552,  0.1949, -0.0973,  0.6671, -1.1011,\n",
      "          0.2994, -0.9529],\n",
      "        [ 0.1610,  0.0054, -0.0847,  0.0691, -0.1432, -0.1653, -0.2491, -0.3015,\n",
      "          0.0695, -0.3644],\n",
      "        [ 0.2532, -0.0539, -0.1568, -0.0044, -0.1443, -0.3656,  0.2104, -0.7889,\n",
      "         -0.3642, -0.8007],\n",
      "        [ 0.3872, -0.1963, -0.4969,  0.3615, -0.0271, -0.1964,  0.1987, -0.0254,\n",
      "         -0.3401, -0.8509],\n",
      "        [ 1.0935, -0.0339,  0.3628,  0.5094,  0.0744, -0.8301,  0.5789,  0.4883,\n",
      "          0.6891,  0.3797],\n",
      "        [ 0.4256,  0.0883, -0.1608,  0.2972, -0.3229, -0.7173, -0.4208, -0.2312,\n",
      "          0.0157, -0.7595]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[[ 0.8946,  0.2482, -0.0143,  ..., -0.0242,  0.4011,  0.0479],\n",
      "         [ 0.1849,  1.0744, -0.3011,  ..., -0.4060,  0.2602,  0.1286],\n",
      "         [ 0.2480, -0.4102,  0.6139,  ..., -0.3277,  0.2656,  0.1224],\n",
      "         ...,\n",
      "         [ 0.3500,  0.4967,  0.1090,  ...,  1.0374,  0.0381,  0.4030],\n",
      "         [-0.3674,  0.6953,  0.1577,  ...,  0.4048, -0.0750, -0.7780],\n",
      "         [-0.2313,  0.6815, -0.2082,  ...,  0.2054,  0.1017,  0.8953]],\n",
      "\n",
      "        [[ 0.6656,  0.2551, -0.0048,  ...,  0.0604,  0.1549, -0.1040],\n",
      "         [-0.3805,  0.9248,  0.1958,  ..., -0.3265, -0.3823, -0.2901],\n",
      "         [-0.2866, -0.2093,  0.6274,  ...,  0.2160, -0.1600, -0.3211],\n",
      "         ...,\n",
      "         [-0.1705,  0.8887,  0.1772,  ...,  0.8499, -0.3578, -0.2866],\n",
      "         [-0.2556, -0.0998, -0.0282,  ...,  0.5679,  0.0453, -0.7014],\n",
      "         [-0.1669,  0.6080,  0.1241,  ..., -0.2954,  0.1866,  0.6533]],\n",
      "\n",
      "        [[ 0.2677,  1.0388,  0.5518,  ..., -0.1538,  0.6298, -0.1034],\n",
      "         [ 0.4449,  1.4030, -0.3042,  ...,  0.2785, -0.6637,  0.1387],\n",
      "         [-0.0841,  0.8410,  1.1474,  ...,  0.0329,  0.0599, -1.1385],\n",
      "         ...,\n",
      "         [-0.3577, -0.4501,  0.3718,  ...,  1.8652,  0.8308, -0.9422],\n",
      "         [-0.4237,  0.1003,  0.3978,  ...,  0.3655,  0.6366, -0.2233],\n",
      "         [-0.5059, -0.1994,  0.8467,  ..., -0.4243, -0.2175,  0.4115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9315,  0.1151,  0.1164,  ...,  0.3115,  0.3238, -0.1462],\n",
      "         [-0.0625,  0.8762, -0.7289,  ..., -0.1423,  0.2623, -0.0695],\n",
      "         [ 0.1146,  0.4739,  1.3374,  ...,  0.1520,  0.1419, -0.1424],\n",
      "         ...,\n",
      "         [ 0.1511,  0.6904, -0.2557,  ...,  1.0127,  0.1609,  0.2212],\n",
      "         [-0.2424,  0.3505,  0.1976,  ...,  0.0872,  0.7999, -0.2983],\n",
      "         [-0.4425,  0.2542, -0.2697,  ..., -0.0184,  0.5816,  1.4233]],\n",
      "\n",
      "        [[ 0.5270,  0.7834,  0.3823,  ..., -0.7322, -0.5138, -0.5566],\n",
      "         [-0.2470,  0.9468, -0.6216,  ...,  0.7913, -0.9865, -0.3349],\n",
      "         [ 0.2340, -0.2625,  1.0509,  ..., -0.5873, -0.1665,  0.3828],\n",
      "         ...,\n",
      "         [ 0.0940,  0.1781, -0.3833,  ...,  1.5075,  0.4895, -0.4300],\n",
      "         [ 0.3897,  0.1135,  0.3806,  ...,  0.1571,  0.7057,  0.5059],\n",
      "         [-0.0782,  0.3207,  0.2222,  ..., -0.2438, -0.7544,  0.6570]],\n",
      "\n",
      "        [[ 0.8545,  0.2400,  0.2285,  ...,  0.4388,  0.1942, -0.3194],\n",
      "         [-0.0695,  1.1166, -0.8019,  ..., -0.3656, -0.0242, -0.4414],\n",
      "         [-0.0286, -0.0237,  0.8161,  ..., -0.2009, -0.1494, -0.2547],\n",
      "         ...,\n",
      "         [ 0.0743,  0.5240, -0.0301,  ...,  0.8898,  0.4111,  0.1879],\n",
      "         [-0.1852,  0.4190, -0.7235,  ...,  0.5051,  0.8245, -0.6268],\n",
      "         [-0.2547,  0.6878, -0.1858,  ..., -0.1739, -0.0771,  1.7234]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    }
   ],
   "source": [
    "## random generate data and test this network\n",
    "d = torch.randn(10,3,100).cuda()\n",
    "test = C(d)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Train this network on ModelNet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main train function for classification\n",
    "def train_cls(train_loader, test_loader, network, optimizer, epochs, scheduler):\n",
    "    reg = OrthoLoss()\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch:[{:02d}/{:02d}]'.format(epoch+1, epochs))\n",
    "        print('Training...')\n",
    "        # .train, batch mean\n",
    "        network.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        for batch, (pos, label) in enumerate(train_loader):\n",
    "            network.zero_grad()\n",
    "            pos, label = pos.cuda(), label.cuda()\n",
    "            \n",
    "            ## TASK 2.7\n",
    "            ## forward propagation\n",
    "            output, trans = network(pos)\n",
    "            loss = nn.functional.nll_loss(nn.functional.log_softmax(output, dim = 1), label)\n",
    "            ##########\n",
    "            \n",
    "            ## regularizer\n",
    "            if trans is not None:\n",
    "                loss += reg(trans) * 0.001\n",
    "\n",
    "            pred = output.max(1)[1]\n",
    "            correct += pred.eq(label).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print('\\rIter: [{:03d}/{:03d}] Loss: {:.4f}'.format(batch+1, len(train_loader), loss.item()), end='', flush=True)\n",
    "        \n",
    "        scheduler.step()\n",
    "        print('\\nAverage Train Loss: {:.4f}; Train Acc: {:.4f}'.format(train_loss/len(train_loader), correct/len(train_loader.dataset) * 100))\n",
    "        \n",
    "        print('\\nTesting...')\n",
    "        with torch.no_grad():\n",
    "            # eval doesn't calcualte gradient, last batch mean, no dropout\n",
    "            network.eval()\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            for batch, (pos, label) in enumerate(test_loader):\n",
    "                pos, label = pos.cuda(), label.cuda()\n",
    "    \n",
    "                ## TASK 2.7\n",
    "                ## forward propagation\n",
    "                output, trans = network(pos)\n",
    "                loss = nn.functional.nll_loss(nn.functional.log_softmax(output, dim = 1), label)\n",
    "\n",
    "                ##########\n",
    "\n",
    "                if trans is not None:\n",
    "                    loss += reg(trans) * 0.001\n",
    "\n",
    "                pred = output.max(1)[1]\n",
    "                correct += pred.eq(label).sum().item()\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                print('\\rIter: [{:03d}/{:03d}] Loss: {:.4f}'.format(batch+1, len(test_loader), loss.item()), end='', flush=True)\n",
    "\n",
    "            print('\\nAverage Test Loss: {:.4f}; Test Acc: {:.4f}'.format(test_loss/len(test_loader), correct/len(test_loader.dataset) * 100))\n",
    "        print('-------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[01/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 1.0431\n",
      "Average Train Loss: 1.6643; Train Acc: 46.1789\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 1.5541\n",
      "Average Test Loss: 1.1715; Test Acc: 59.2511\n",
      "-------------------------------------------\n",
      "Epoch:[02/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 1.2018\n",
      "Average Train Loss: 1.0418; Train Acc: 66.7502\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.2933\n",
      "Average Test Loss: 0.9675; Test Acc: 64.3172\n",
      "-------------------------------------------\n",
      "Epoch:[03/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 1.2838\n",
      "Average Train Loss: 0.9357; Train Acc: 70.1579\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.6684\n",
      "Average Test Loss: 1.1025; Test Acc: 60.9031\n",
      "-------------------------------------------\n",
      "Epoch:[04/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.8934\n",
      "Average Train Loss: 0.8105; Train Acc: 74.5928\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0889\n",
      "Average Test Loss: 0.9539; Test Acc: 64.5374\n",
      "-------------------------------------------\n",
      "Epoch:[05/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5806\n",
      "Average Train Loss: 0.7515; Train Acc: 75.2944\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.9556\n",
      "Average Test Loss: 1.0155; Test Acc: 65.0881\n",
      "-------------------------------------------\n",
      "Epoch:[06/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.6926\n",
      "Average Train Loss: 0.7356; Train Acc: 75.7454\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.5572\n",
      "Average Test Loss: 0.8602; Test Acc: 69.4934\n",
      "-------------------------------------------\n",
      "Epoch:[07/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5312\n",
      "Average Train Loss: 0.6516; Train Acc: 77.7249\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.4570\n",
      "Average Test Loss: 0.9481; Test Acc: 65.9692\n",
      "-------------------------------------------\n",
      "Epoch:[08/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3862\n",
      "Average Train Loss: 0.6513; Train Acc: 78.1759\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 1.26361\n",
      "Average Test Loss: 1.0952; Test Acc: 68.6123\n",
      "-------------------------------------------\n",
      "Epoch:[09/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.7087\n",
      "Average Train Loss: 0.6345; Train Acc: 78.3513\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0551\n",
      "Average Test Loss: 0.7188; Test Acc: 75.4405\n",
      "-------------------------------------------\n",
      "Epoch:[10/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3538\n",
      "Average Train Loss: 0.5728; Train Acc: 80.1303\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0111\n",
      "Average Test Loss: 0.6302; Test Acc: 80.1762\n",
      "-------------------------------------------\n",
      "Epoch:[11/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4663\n",
      "Average Train Loss: 0.5516; Train Acc: 81.4833\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0592\n",
      "Average Test Loss: 0.6532; Test Acc: 78.4141\n",
      "-------------------------------------------\n",
      "Epoch:[12/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4510\n",
      "Average Train Loss: 0.5510; Train Acc: 81.2077\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 2.47906\n",
      "Average Test Loss: 0.7548; Test Acc: 75.4405\n",
      "-------------------------------------------\n",
      "Epoch:[13/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.7192\n",
      "Average Train Loss: 0.5080; Train Acc: 83.3626\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0332\n",
      "Average Test Loss: 0.9560; Test Acc: 63.4361\n",
      "-------------------------------------------\n",
      "Epoch:[14/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4768\n",
      "Average Train Loss: 0.5135; Train Acc: 82.6359\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.1175\n",
      "Average Test Loss: 0.7987; Test Acc: 70.1542\n",
      "-------------------------------------------\n",
      "Epoch:[15/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5365\n",
      "Average Train Loss: 0.5087; Train Acc: 82.8364\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.6252\n",
      "Average Test Loss: 0.7648; Test Acc: 74.2291\n",
      "-------------------------------------------\n",
      "Epoch:[16/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.6505\n",
      "Average Train Loss: 0.4481; Train Acc: 84.3648\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 2.53430\n",
      "Average Test Loss: 0.8454; Test Acc: 70.3744\n",
      "-------------------------------------------\n",
      "Epoch:[17/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5524\n",
      "Average Train Loss: 0.4630; Train Acc: 84.6154\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0588\n",
      "Average Test Loss: 0.5666; Test Acc: 81.9383\n",
      "-------------------------------------------\n",
      "Epoch:[18/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3609\n",
      "Average Train Loss: 0.4573; Train Acc: 83.9389\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 1.93631\n",
      "Average Test Loss: 0.6314; Test Acc: 79.7357\n",
      "-------------------------------------------\n",
      "Epoch:[19/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5465\n",
      "Average Train Loss: 0.4314; Train Acc: 85.2418\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00894\n",
      "Average Test Loss: 0.6059; Test Acc: 77.6432\n",
      "-------------------------------------------\n",
      "Epoch:[20/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.6855\n",
      "Average Train Loss: 0.4558; Train Acc: 84.8910\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 4.07348\n",
      "Average Test Loss: 1.2997; Test Acc: 61.7841\n",
      "-------------------------------------------\n",
      "Epoch:[21/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.9020\n",
      "Average Train Loss: 0.3716; Train Acc: 87.5720\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0314\n",
      "Average Test Loss: 0.3901; Test Acc: 87.5551\n",
      "-------------------------------------------\n",
      "Epoch:[22/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1684\n",
      "Average Train Loss: 0.3561; Train Acc: 88.1483\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.1221\n",
      "Average Test Loss: 0.4264; Test Acc: 86.2335\n",
      "-------------------------------------------\n",
      "Epoch:[23/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.6542\n",
      "Average Train Loss: 0.3552; Train Acc: 88.3989\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0248\n",
      "Average Test Loss: 0.4690; Test Acc: 86.5639\n",
      "-------------------------------------------\n",
      "Epoch:[24/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.7562\n",
      "Average Train Loss: 0.3322; Train Acc: 88.6745\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 1.0334\n",
      "Average Test Loss: 0.4708; Test Acc: 84.3612\n",
      "-------------------------------------------\n",
      "Epoch:[25/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1966\n",
      "Average Train Loss: 0.3324; Train Acc: 89.0504\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0740\n",
      "Average Test Loss: 0.4081; Test Acc: 84.9119\n",
      "-------------------------------------------\n",
      "Epoch:[26/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2144\n",
      "Average Train Loss: 0.3180; Train Acc: 88.9752\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.1047\n",
      "Average Test Loss: 0.4242; Test Acc: 86.5639\n",
      "-------------------------------------------\n",
      "Epoch:[27/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2308\n",
      "Average Train Loss: 0.3478; Train Acc: 88.4490\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.5136\n",
      "Average Test Loss: 0.4459; Test Acc: 85.3524\n",
      "-------------------------------------------\n",
      "Epoch:[28/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1873\n",
      "Average Train Loss: 0.3394; Train Acc: 88.6745\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 1.0052\n",
      "Average Test Loss: 0.7434; Test Acc: 75.7709\n",
      "-------------------------------------------\n",
      "Epoch:[29/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2299\n",
      "Average Train Loss: 0.3054; Train Acc: 89.5264\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 1.3459\n",
      "Average Test Loss: 0.5054; Test Acc: 82.8194\n",
      "-------------------------------------------\n",
      "Epoch:[30/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4007\n",
      "Average Train Loss: 0.3282; Train Acc: 88.7497\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0051\n",
      "Average Test Loss: 0.5175; Test Acc: 79.9559\n",
      "-------------------------------------------\n",
      "Epoch:[31/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3484\n",
      "Average Train Loss: 0.3036; Train Acc: 89.5014\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0050\n",
      "Average Test Loss: 0.4266; Test Acc: 85.1322\n",
      "-------------------------------------------\n",
      "Epoch:[32/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2195\n",
      "Average Train Loss: 0.3123; Train Acc: 89.4513\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.81951\n",
      "Average Test Loss: 0.4100; Test Acc: 87.7753\n",
      "-------------------------------------------\n",
      "Epoch:[33/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4373\n",
      "Average Train Loss: 0.3160; Train Acc: 89.0003\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0329\n",
      "Average Test Loss: 0.4076; Test Acc: 85.7930\n",
      "-------------------------------------------\n",
      "Epoch:[34/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5246\n",
      "Average Train Loss: 0.3068; Train Acc: 89.7018\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0481\n",
      "Average Test Loss: 0.4979; Test Acc: 82.0485\n",
      "-------------------------------------------\n",
      "Epoch:[35/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4136\n",
      "Average Train Loss: 0.2984; Train Acc: 89.5264\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 4.44251\n",
      "Average Test Loss: 0.7249; Test Acc: 72.6872\n",
      "-------------------------------------------\n",
      "Epoch:[36/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.7809\n",
      "Average Train Loss: 0.3210; Train Acc: 89.0253\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0082\n",
      "Average Test Loss: 0.3296; Test Acc: 89.3172\n",
      "-------------------------------------------\n",
      "Epoch:[37/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.6900\n",
      "Average Train Loss: 0.2896; Train Acc: 90.0276\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.6412\n",
      "Average Test Loss: 0.4560; Test Acc: 86.1233\n",
      "-------------------------------------------\n",
      "Epoch:[38/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3449\n",
      "Average Train Loss: 0.3185; Train Acc: 89.1756\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.1795\n",
      "Average Test Loss: 0.3815; Test Acc: 88.2159\n",
      "-------------------------------------------\n",
      "Epoch:[39/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2801\n",
      "Average Train Loss: 0.2872; Train Acc: 90.1278\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.4114\n",
      "Average Test Loss: 0.5317; Test Acc: 80.7269\n",
      "-------------------------------------------\n",
      "Epoch:[40/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1888\n",
      "Average Train Loss: 0.2784; Train Acc: 90.2531\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00420\n",
      "Average Test Loss: 0.4797; Test Acc: 82.4890\n",
      "-------------------------------------------\n",
      "Epoch:[41/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3471\n",
      "Average Train Loss: 0.2510; Train Acc: 91.1551\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0228\n",
      "Average Test Loss: 0.3450; Test Acc: 88.9868\n",
      "-------------------------------------------\n",
      "Epoch:[42/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1440\n",
      "Average Train Loss: 0.2319; Train Acc: 91.9820\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0232\n",
      "Average Test Loss: 0.3826; Test Acc: 87.3348\n",
      "-------------------------------------------\n",
      "Epoch:[43/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3046\n",
      "Average Train Loss: 0.2465; Train Acc: 91.6562\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.1130\n",
      "Average Test Loss: 0.3824; Test Acc: 86.0132\n",
      "-------------------------------------------\n",
      "Epoch:[44/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1443\n",
      "Average Train Loss: 0.2281; Train Acc: 92.4831\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0404\n",
      "Average Test Loss: 0.4061; Test Acc: 85.2423\n",
      "-------------------------------------------\n",
      "Epoch:[45/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1890\n",
      "Average Train Loss: 0.2322; Train Acc: 92.1323\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.4506\n",
      "Average Test Loss: 0.3724; Test Acc: 85.9031\n",
      "-------------------------------------------\n",
      "Epoch:[46/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2638\n",
      "Average Train Loss: 0.2207; Train Acc: 92.6334\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0081\n",
      "Average Test Loss: 0.4386; Test Acc: 83.4802\n",
      "-------------------------------------------\n",
      "Epoch:[47/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3831\n",
      "Average Train Loss: 0.2302; Train Acc: 92.1824\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00607\n",
      "Average Test Loss: 0.3197; Test Acc: 90.5286\n",
      "-------------------------------------------\n",
      "Epoch:[48/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5665\n",
      "Average Train Loss: 0.2285; Train Acc: 92.2576\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01534\n",
      "Average Test Loss: 0.3570; Test Acc: 88.5463\n",
      "-------------------------------------------\n",
      "Epoch:[49/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3152\n",
      "Average Train Loss: 0.2081; Train Acc: 92.6334\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0068\n",
      "Average Test Loss: 0.3426; Test Acc: 87.4449\n",
      "-------------------------------------------\n",
      "Epoch:[50/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0670\n",
      "Average Train Loss: 0.2103; Train Acc: 92.8589\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01411\n",
      "Average Test Loss: 0.3263; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[51/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3530\n",
      "Average Train Loss: 0.2016; Train Acc: 92.7587\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0075\n",
      "Average Test Loss: 0.4279; Test Acc: 84.3612\n",
      "-------------------------------------------\n",
      "Epoch:[52/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1014\n",
      "Average Train Loss: 0.2191; Train Acc: 92.5833\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.10833\n",
      "Average Test Loss: 0.3770; Test Acc: 88.1057\n",
      "-------------------------------------------\n",
      "Epoch:[53/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1030\n",
      "Average Train Loss: 0.2111; Train Acc: 93.1847\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0868\n",
      "Average Test Loss: 0.4318; Test Acc: 84.6916\n",
      "-------------------------------------------\n",
      "Epoch:[54/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4459\n",
      "Average Train Loss: 0.2246; Train Acc: 92.4831\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0065\n",
      "Average Test Loss: 0.4378; Test Acc: 84.4714\n",
      "-------------------------------------------\n",
      "Epoch:[55/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1111\n",
      "Average Train Loss: 0.2099; Train Acc: 92.4330\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0151\n",
      "Average Test Loss: 0.3846; Test Acc: 86.5639\n",
      "-------------------------------------------\n",
      "Epoch:[56/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5476\n",
      "Average Train Loss: 0.2009; Train Acc: 93.0594\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0039\n",
      "Average Test Loss: 0.3103; Test Acc: 88.8767\n",
      "-------------------------------------------\n",
      "Epoch:[57/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1291\n",
      "Average Train Loss: 0.2037; Train Acc: 93.2348\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.14123\n",
      "Average Test Loss: 0.3361; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[58/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0554\n",
      "Average Train Loss: 0.2050; Train Acc: 92.7086\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0218\n",
      "Average Test Loss: 0.3305; Test Acc: 89.3172\n",
      "-------------------------------------------\n",
      "Epoch:[59/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4702\n",
      "Average Train Loss: 0.2068; Train Acc: 92.7587\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.2320\n",
      "Average Test Loss: 0.4056; Test Acc: 85.4626\n",
      "-------------------------------------------\n",
      "Epoch:[60/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0551\n",
      "Average Train Loss: 0.1990; Train Acc: 92.9090\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0574\n",
      "Average Test Loss: 0.4295; Test Acc: 85.4626\n",
      "-------------------------------------------\n",
      "Epoch:[61/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0241\n",
      "Average Train Loss: 0.1847; Train Acc: 93.3350\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0055\n",
      "Average Test Loss: 0.3110; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[62/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3056\n",
      "Average Train Loss: 0.1678; Train Acc: 93.9614\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0422\n",
      "Average Test Loss: 0.3686; Test Acc: 87.2247\n",
      "-------------------------------------------\n",
      "Epoch:[63/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1350\n",
      "Average Train Loss: 0.1744; Train Acc: 93.9113\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0585\n",
      "Average Test Loss: 0.4010; Test Acc: 86.1233\n",
      "-------------------------------------------\n",
      "Epoch:[64/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2554\n",
      "Average Train Loss: 0.1882; Train Acc: 93.1346\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.49702\n",
      "Average Test Loss: 0.3842; Test Acc: 87.0044\n",
      "-------------------------------------------\n",
      "Epoch:[65/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0764\n",
      "Average Train Loss: 0.1770; Train Acc: 93.7610\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0091\n",
      "Average Test Loss: 0.3129; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[66/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1807\n",
      "Average Train Loss: 0.1735; Train Acc: 93.8612\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0186\n",
      "Average Test Loss: 0.3948; Test Acc: 86.4537\n",
      "-------------------------------------------\n",
      "Epoch:[67/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.6438\n",
      "Average Train Loss: 0.1640; Train Acc: 94.2621\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0030\n",
      "Average Test Loss: 0.3547; Test Acc: 87.9956\n",
      "-------------------------------------------\n",
      "Epoch:[68/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1752\n",
      "Average Train Loss: 0.1606; Train Acc: 93.9364\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.02704\n",
      "Average Test Loss: 0.2896; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[69/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0176\n",
      "Average Train Loss: 0.1551; Train Acc: 94.7632\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00386\n",
      "Average Test Loss: 0.3566; Test Acc: 87.4449\n",
      "-------------------------------------------\n",
      "Epoch:[70/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0331\n",
      "Average Train Loss: 0.1676; Train Acc: 94.1869\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01091\n",
      "Average Test Loss: 0.3307; Test Acc: 89.2070\n",
      "-------------------------------------------\n",
      "Epoch:[71/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2315\n",
      "Average Train Loss: 0.1650; Train Acc: 94.2621\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0025\n",
      "Average Test Loss: 0.3028; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[72/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.5391\n",
      "Average Train Loss: 0.1632; Train Acc: 94.0616\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0083\n",
      "Average Test Loss: 0.3463; Test Acc: 88.3260\n",
      "-------------------------------------------\n",
      "Epoch:[73/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2042\n",
      "Average Train Loss: 0.1628; Train Acc: 94.5377\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.05486\n",
      "Average Test Loss: 0.4429; Test Acc: 84.0308\n",
      "-------------------------------------------\n",
      "Epoch:[74/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0974\n",
      "Average Train Loss: 0.1489; Train Acc: 94.6379\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00801\n",
      "Average Test Loss: 0.3185; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[75/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0881\n",
      "Average Train Loss: 0.1519; Train Acc: 94.4375\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0143\n",
      "Average Test Loss: 0.2971; Test Acc: 90.7489\n",
      "-------------------------------------------\n",
      "Epoch:[76/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1581\n",
      "Average Train Loss: 0.1600; Train Acc: 94.4124\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0073\n",
      "Average Test Loss: 0.3520; Test Acc: 88.3260\n",
      "-------------------------------------------\n",
      "Epoch:[77/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1209\n",
      "Average Train Loss: 0.1486; Train Acc: 94.5628\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0120\n",
      "Average Test Loss: 0.3094; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[78/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2303\n",
      "Average Train Loss: 0.1623; Train Acc: 94.8133\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0078\n",
      "Average Test Loss: 0.2920; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[79/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2369\n",
      "Average Train Loss: 0.1508; Train Acc: 94.9136\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0033\n",
      "Average Test Loss: 0.3158; Test Acc: 88.8767\n",
      "-------------------------------------------\n",
      "Epoch:[80/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0913\n",
      "Average Train Loss: 0.1595; Train Acc: 94.4375\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0093\n",
      "Average Test Loss: 0.3076; Test Acc: 89.6476\n",
      "-------------------------------------------\n",
      "Epoch:[81/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0173\n",
      "Average Train Loss: 0.1404; Train Acc: 94.9386\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0076\n",
      "Average Test Loss: 0.3151; Test Acc: 88.8767\n",
      "-------------------------------------------\n",
      "Epoch:[82/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1949\n",
      "Average Train Loss: 0.1532; Train Acc: 94.4375\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01819\n",
      "Average Test Loss: 0.3016; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[83/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3328\n",
      "Average Train Loss: 0.1323; Train Acc: 95.3896\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01116\n",
      "Average Test Loss: 0.3089; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[84/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0769\n",
      "Average Train Loss: 0.1328; Train Acc: 95.3145\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01126\n",
      "Average Test Loss: 0.2955; Test Acc: 90.4185\n",
      "-------------------------------------------\n",
      "Epoch:[85/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0083\n",
      "Average Train Loss: 0.1396; Train Acc: 94.9887\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.02025\n",
      "Average Test Loss: 0.2853; Test Acc: 91.6300\n",
      "-------------------------------------------\n",
      "Epoch:[86/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2061\n",
      "Average Train Loss: 0.1401; Train Acc: 95.3395\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00468\n",
      "Average Test Loss: 0.2968; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[87/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1232\n",
      "Average Train Loss: 0.1243; Train Acc: 95.1892\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00609\n",
      "Average Test Loss: 0.3117; Test Acc: 89.4273\n",
      "-------------------------------------------\n",
      "Epoch:[88/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1846\n",
      "Average Train Loss: 0.1173; Train Acc: 95.6652\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0236\n",
      "Average Test Loss: 0.3140; Test Acc: 89.2070\n",
      "-------------------------------------------\n",
      "Epoch:[89/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3580\n",
      "Average Train Loss: 0.1305; Train Acc: 95.2142\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.02380\n",
      "Average Test Loss: 0.4031; Test Acc: 86.4537\n",
      "-------------------------------------------\n",
      "Epoch:[90/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0606\n",
      "Average Train Loss: 0.1301; Train Acc: 95.0890\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01229\n",
      "Average Test Loss: 0.2961; Test Acc: 90.7489\n",
      "-------------------------------------------\n",
      "Epoch:[91/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2258\n",
      "Average Train Loss: 0.1363; Train Acc: 95.3896\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00937\n",
      "Average Test Loss: 0.2972; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[92/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1591\n",
      "Average Train Loss: 0.1282; Train Acc: 95.3145\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0031\n",
      "Average Test Loss: 0.2766; Test Acc: 90.6388\n",
      "-------------------------------------------\n",
      "Epoch:[93/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1329\n",
      "Average Train Loss: 0.1323; Train Acc: 95.1140\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00480\n",
      "Average Test Loss: 0.3003; Test Acc: 89.0969\n",
      "-------------------------------------------\n",
      "Epoch:[94/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1018\n",
      "Average Train Loss: 0.1246; Train Acc: 95.5650\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00694\n",
      "Average Test Loss: 0.3087; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[95/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3873\n",
      "Average Train Loss: 0.1218; Train Acc: 95.8156\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00781\n",
      "Average Test Loss: 0.3092; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[96/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0610\n",
      "Average Train Loss: 0.1280; Train Acc: 95.4899\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0138\n",
      "Average Test Loss: 0.3114; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[97/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1034\n",
      "Average Train Loss: 0.1315; Train Acc: 95.3896\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0062\n",
      "Average Test Loss: 0.3075; Test Acc: 89.4273\n",
      "-------------------------------------------\n",
      "Epoch:[98/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0358\n",
      "Average Train Loss: 0.1267; Train Acc: 95.4899\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.0121\n",
      "Average Test Loss: 0.3396; Test Acc: 88.1057\n",
      "-------------------------------------------\n",
      "Epoch:[99/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1062\n",
      "Average Train Loss: 0.1277; Train Acc: 95.4648\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01986\n",
      "Average Test Loss: 0.3046; Test Acc: 90.4185\n",
      "-------------------------------------------\n",
      "Epoch:[100/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1366\n",
      "Average Train Loss: 0.1399; Train Acc: 95.2393\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.03792\n",
      "Average Test Loss: 0.3363; Test Acc: 89.0969\n",
      "-------------------------------------------\n",
      "Epoch:[101/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0682\n",
      "Average Train Loss: 0.1236; Train Acc: 95.5650\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01780\n",
      "Average Test Loss: 0.3095; Test Acc: 89.6476\n",
      "-------------------------------------------\n",
      "Epoch:[102/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3125\n",
      "Average Train Loss: 0.1195; Train Acc: 95.6151\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01011\n",
      "Average Test Loss: 0.3051; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[103/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1495\n",
      "Average Train Loss: 0.1201; Train Acc: 95.7404\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01276\n",
      "Average Test Loss: 0.3103; Test Acc: 89.4273\n",
      "-------------------------------------------\n",
      "Epoch:[104/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1172\n",
      "Average Train Loss: 0.1180; Train Acc: 95.5149\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01793\n",
      "Average Test Loss: 0.3257; Test Acc: 88.5463\n",
      "-------------------------------------------\n",
      "Epoch:[105/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2264\n",
      "Average Train Loss: 0.1143; Train Acc: 95.8156\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00691\n",
      "Average Test Loss: 0.3181; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[106/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0244\n",
      "Average Train Loss: 0.1134; Train Acc: 95.8657\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00877\n",
      "Average Test Loss: 0.3037; Test Acc: 89.6476\n",
      "-------------------------------------------\n",
      "Epoch:[107/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3970\n",
      "Average Train Loss: 0.1156; Train Acc: 95.7404\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01299\n",
      "Average Test Loss: 0.3093; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[108/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1160\n",
      "Average Train Loss: 0.1138; Train Acc: 95.8156\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01226\n",
      "Average Test Loss: 0.3255; Test Acc: 89.2070\n",
      "-------------------------------------------\n",
      "Epoch:[109/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1218\n",
      "Average Train Loss: 0.1109; Train Acc: 95.7905\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01248\n",
      "Average Test Loss: 0.3129; Test Acc: 89.3172\n",
      "-------------------------------------------\n",
      "Epoch:[110/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0811\n",
      "Average Train Loss: 0.1209; Train Acc: 95.5149\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00770\n",
      "Average Test Loss: 0.3004; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[111/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3156\n",
      "Average Train Loss: 0.1210; Train Acc: 95.9910\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.02504\n",
      "Average Test Loss: 0.3361; Test Acc: 88.7665\n",
      "-------------------------------------------\n",
      "Epoch:[112/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3331\n",
      "Average Train Loss: 0.1139; Train Acc: 96.1413\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01280\n",
      "Average Test Loss: 0.3022; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[113/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1369\n",
      "Average Train Loss: 0.1164; Train Acc: 95.5650\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01652\n",
      "Average Test Loss: 0.2966; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[114/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0654\n",
      "Average Train Loss: 0.1224; Train Acc: 95.8156\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00837\n",
      "Average Test Loss: 0.2898; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[115/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0917\n",
      "Average Train Loss: 0.1100; Train Acc: 95.9910\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00922\n",
      "Average Test Loss: 0.2913; Test Acc: 90.5286\n",
      "-------------------------------------------\n",
      "Epoch:[116/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0400\n",
      "Average Train Loss: 0.1158; Train Acc: 95.9409\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01066\n",
      "Average Test Loss: 0.3227; Test Acc: 89.3172\n",
      "-------------------------------------------\n",
      "Epoch:[117/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2330\n",
      "Average Train Loss: 0.1297; Train Acc: 95.0890\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00978\n",
      "Average Test Loss: 0.3259; Test Acc: 88.5463\n",
      "-------------------------------------------\n",
      "Epoch:[118/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1905\n",
      "Average Train Loss: 0.1120; Train Acc: 95.9659\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00541\n",
      "Average Test Loss: 0.3169; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[119/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2166\n",
      "Average Train Loss: 0.1093; Train Acc: 96.2165\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01303\n",
      "Average Test Loss: 0.3123; Test Acc: 89.3172\n",
      "-------------------------------------------\n",
      "Epoch:[120/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0459\n",
      "Average Train Loss: 0.1180; Train Acc: 95.8657\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01363\n",
      "Average Test Loss: 0.3195; Test Acc: 89.0969\n",
      "-------------------------------------------\n",
      "Epoch:[121/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2257\n",
      "Average Train Loss: 0.1147; Train Acc: 95.6652\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00836\n",
      "Average Test Loss: 0.2984; Test Acc: 90.5286\n",
      "-------------------------------------------\n",
      "Epoch:[122/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1915\n",
      "Average Train Loss: 0.1055; Train Acc: 96.2415\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01289\n",
      "Average Test Loss: 0.3151; Test Acc: 89.4273\n",
      "-------------------------------------------\n",
      "Epoch:[123/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0574\n",
      "Average Train Loss: 0.1070; Train Acc: 95.9910\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01107\n",
      "Average Test Loss: 0.3121; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[124/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0919\n",
      "Average Train Loss: 0.1129; Train Acc: 95.9659\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00834\n",
      "Average Test Loss: 0.3063; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[125/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0708\n",
      "Average Train Loss: 0.1096; Train Acc: 95.8657\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01450\n",
      "Average Test Loss: 0.3095; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[126/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0605\n",
      "Average Train Loss: 0.1172; Train Acc: 96.0160\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01190\n",
      "Average Test Loss: 0.3185; Test Acc: 89.3172\n",
      "-------------------------------------------\n",
      "Epoch:[127/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1127\n",
      "Average Train Loss: 0.1128; Train Acc: 95.6903\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00593\n",
      "Average Test Loss: 0.3082; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[128/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4211\n",
      "Average Train Loss: 0.1087; Train Acc: 95.9910\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00415\n",
      "Average Test Loss: 0.3035; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[129/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2706\n",
      "Average Train Loss: 0.1100; Train Acc: 96.2165\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00997\n",
      "Average Test Loss: 0.3083; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[130/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2581\n",
      "Average Train Loss: 0.1047; Train Acc: 96.2917\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00925\n",
      "Average Test Loss: 0.3094; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[131/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0593\n",
      "Average Train Loss: 0.1015; Train Acc: 96.2917\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00481\n",
      "Average Test Loss: 0.2927; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[132/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0198\n",
      "Average Train Loss: 0.1125; Train Acc: 95.8406\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00687\n",
      "Average Test Loss: 0.2952; Test Acc: 90.4185\n",
      "-------------------------------------------\n",
      "Epoch:[133/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0746\n",
      "Average Train Loss: 0.1064; Train Acc: 95.7905\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01140\n",
      "Average Test Loss: 0.3214; Test Acc: 89.3172\n",
      "-------------------------------------------\n",
      "Epoch:[134/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0089\n",
      "Average Train Loss: 0.1187; Train Acc: 95.6151\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00595\n",
      "Average Test Loss: 0.3226; Test Acc: 88.3260\n",
      "-------------------------------------------\n",
      "Epoch:[135/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2615\n",
      "Average Train Loss: 0.1038; Train Acc: 96.3167\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00637\n",
      "Average Test Loss: 0.3148; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[136/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1963\n",
      "Average Train Loss: 0.1064; Train Acc: 96.2666\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00774\n",
      "Average Test Loss: 0.3019; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[137/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4454\n",
      "Average Train Loss: 0.1082; Train Acc: 95.8406\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01311\n",
      "Average Test Loss: 0.3029; Test Acc: 90.6388\n",
      "-------------------------------------------\n",
      "Epoch:[138/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0650\n",
      "Average Train Loss: 0.1010; Train Acc: 96.1163\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01120\n",
      "Average Test Loss: 0.3057; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[139/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0276\n",
      "Average Train Loss: 0.1162; Train Acc: 95.7905\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01470\n",
      "Average Test Loss: 0.3317; Test Acc: 89.2070\n",
      "-------------------------------------------\n",
      "Epoch:[140/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0544\n",
      "Average Train Loss: 0.1068; Train Acc: 96.0912\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01155\n",
      "Average Test Loss: 0.3137; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[141/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0290\n",
      "Average Train Loss: 0.0975; Train Acc: 96.6926\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01375\n",
      "Average Test Loss: 0.3191; Test Acc: 89.5374\n",
      "-------------------------------------------\n",
      "Epoch:[142/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0713\n",
      "Average Train Loss: 0.1039; Train Acc: 96.2165\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00636\n",
      "Average Test Loss: 0.3203; Test Acc: 89.3172\n",
      "-------------------------------------------\n",
      "Epoch:[143/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0448\n",
      "Average Train Loss: 0.1039; Train Acc: 96.0411\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01082\n",
      "Average Test Loss: 0.3129; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[144/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2752\n",
      "Average Train Loss: 0.1059; Train Acc: 96.3418\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01148\n",
      "Average Test Loss: 0.3097; Test Acc: 89.5374\n",
      "-------------------------------------------\n",
      "Epoch:[145/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1030\n",
      "Average Train Loss: 0.1097; Train Acc: 96.1914\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01083\n",
      "Average Test Loss: 0.3052; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[146/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1478\n",
      "Average Train Loss: 0.0971; Train Acc: 96.6174\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01277\n",
      "Average Test Loss: 0.3174; Test Acc: 89.6476\n",
      "-------------------------------------------\n",
      "Epoch:[147/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2372\n",
      "Average Train Loss: 0.1061; Train Acc: 95.9659\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01095\n",
      "Average Test Loss: 0.3087; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[148/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2212\n",
      "Average Train Loss: 0.1050; Train Acc: 96.2666\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01379\n",
      "Average Test Loss: 0.3101; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[149/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1234\n",
      "Average Train Loss: 0.1054; Train Acc: 96.0912\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00875\n",
      "Average Test Loss: 0.2989; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[150/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1231\n",
      "Average Train Loss: 0.1003; Train Acc: 96.3418\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01174\n",
      "Average Test Loss: 0.3090; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[151/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0371\n",
      "Average Train Loss: 0.1004; Train Acc: 96.4921\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00726\n",
      "Average Test Loss: 0.3023; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[152/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0285\n",
      "Average Train Loss: 0.1022; Train Acc: 96.1914\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00726\n",
      "Average Test Loss: 0.3087; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[153/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1546\n",
      "Average Train Loss: 0.1074; Train Acc: 96.0160\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01053\n",
      "Average Test Loss: 0.3081; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[154/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0450\n",
      "Average Train Loss: 0.1002; Train Acc: 96.4671\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01203\n",
      "Average Test Loss: 0.3001; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[155/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0583\n",
      "Average Train Loss: 0.1075; Train Acc: 95.8908\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00762\n",
      "Average Test Loss: 0.3027; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[156/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0102\n",
      "Average Train Loss: 0.0975; Train Acc: 96.7176\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00839\n",
      "Average Test Loss: 0.3042; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[157/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1113\n",
      "Average Train Loss: 0.1085; Train Acc: 96.1664\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01382\n",
      "Average Test Loss: 0.3148; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[158/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0174\n",
      "Average Train Loss: 0.0950; Train Acc: 96.4671\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01109\n",
      "Average Test Loss: 0.3153; Test Acc: 89.4273\n",
      "-------------------------------------------\n",
      "Epoch:[159/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0640\n",
      "Average Train Loss: 0.0974; Train Acc: 96.4169\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01388\n",
      "Average Test Loss: 0.3077; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[160/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0633\n",
      "Average Train Loss: 0.0983; Train Acc: 96.6174\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01121\n",
      "Average Test Loss: 0.3028; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[161/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0302\n",
      "Average Train Loss: 0.1041; Train Acc: 96.2165\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00761\n",
      "Average Test Loss: 0.3112; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[162/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0882\n",
      "Average Train Loss: 0.0974; Train Acc: 96.5422\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01147\n",
      "Average Test Loss: 0.3032; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[163/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1551\n",
      "Average Train Loss: 0.1006; Train Acc: 96.4420\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00780\n",
      "Average Test Loss: 0.3100; Test Acc: 90.4185\n",
      "-------------------------------------------\n",
      "Epoch:[164/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4019\n",
      "Average Train Loss: 0.1130; Train Acc: 95.9659\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00690\n",
      "Average Test Loss: 0.3070; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[165/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0316\n",
      "Average Train Loss: 0.0985; Train Acc: 96.2666\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00904\n",
      "Average Test Loss: 0.3177; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[166/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1072\n",
      "Average Train Loss: 0.0966; Train Acc: 96.4921\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00765\n",
      "Average Test Loss: 0.3110; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[167/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0378\n",
      "Average Train Loss: 0.1065; Train Acc: 95.9910\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00687\n",
      "Average Test Loss: 0.2948; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[168/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1423\n",
      "Average Train Loss: 0.1048; Train Acc: 96.0411\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01335\n",
      "Average Test Loss: 0.3092; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[169/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0519\n",
      "Average Train Loss: 0.0970; Train Acc: 96.5422\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01314\n",
      "Average Test Loss: 0.3079; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[170/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0301\n",
      "Average Train Loss: 0.1022; Train Acc: 96.0661\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00722\n",
      "Average Test Loss: 0.3114; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[171/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0110\n",
      "Average Train Loss: 0.0981; Train Acc: 96.3167\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01486\n",
      "Average Test Loss: 0.3118; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[172/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0393\n",
      "Average Train Loss: 0.0986; Train Acc: 96.4420\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00751\n",
      "Average Test Loss: 0.3181; Test Acc: 89.5374\n",
      "-------------------------------------------\n",
      "Epoch:[173/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1297\n",
      "Average Train Loss: 0.0968; Train Acc: 96.6174\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00941\n",
      "Average Test Loss: 0.3112; Test Acc: 89.7577\n",
      "-------------------------------------------\n",
      "Epoch:[174/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2024\n",
      "Average Train Loss: 0.0967; Train Acc: 96.1413\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01396\n",
      "Average Test Loss: 0.3087; Test Acc: 89.5374\n",
      "-------------------------------------------\n",
      "Epoch:[175/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.3389\n",
      "Average Train Loss: 0.0974; Train Acc: 96.6926\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00739\n",
      "Average Test Loss: 0.2998; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[176/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1069\n",
      "Average Train Loss: 0.0945; Train Acc: 96.5673\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01132\n",
      "Average Test Loss: 0.3033; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[177/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1361\n",
      "Average Train Loss: 0.1011; Train Acc: 96.4671\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00966\n",
      "Average Test Loss: 0.3105; Test Acc: 89.6476\n",
      "-------------------------------------------\n",
      "Epoch:[178/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2728\n",
      "Average Train Loss: 0.0998; Train Acc: 96.6675\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00989\n",
      "Average Test Loss: 0.3076; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[179/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.2119\n",
      "Average Train Loss: 0.0985; Train Acc: 96.5172\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01023\n",
      "Average Test Loss: 0.2967; Test Acc: 90.6388\n",
      "-------------------------------------------\n",
      "Epoch:[180/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0188\n",
      "Average Train Loss: 0.1024; Train Acc: 96.1664\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01424\n",
      "Average Test Loss: 0.3032; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[181/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0637\n",
      "Average Train Loss: 0.0952; Train Acc: 96.6926\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01040\n",
      "Average Test Loss: 0.3032; Test Acc: 89.9780\n",
      "-------------------------------------------\n",
      "Epoch:[182/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1097\n",
      "Average Train Loss: 0.1058; Train Acc: 96.1664\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00711\n",
      "Average Test Loss: 0.3104; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[183/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4020\n",
      "Average Train Loss: 0.0932; Train Acc: 96.7427\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01249\n",
      "Average Test Loss: 0.3079; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[184/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0528\n",
      "Average Train Loss: 0.0969; Train Acc: 96.4921\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01203\n",
      "Average Test Loss: 0.3012; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[185/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.4094\n",
      "Average Train Loss: 0.0966; Train Acc: 96.4671\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01157\n",
      "Average Test Loss: 0.3124; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[186/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0720\n",
      "Average Train Loss: 0.0900; Train Acc: 96.5923\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01323\n",
      "Average Test Loss: 0.3113; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[187/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1934\n",
      "Average Train Loss: 0.1069; Train Acc: 96.2165\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01084\n",
      "Average Test Loss: 0.3025; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[188/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0590\n",
      "Average Train Loss: 0.0922; Train Acc: 96.6675\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01163\n",
      "Average Test Loss: 0.3114; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[189/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0185\n",
      "Average Train Loss: 0.0979; Train Acc: 96.3668\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00924\n",
      "Average Test Loss: 0.3079; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[190/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1023\n",
      "Average Train Loss: 0.1017; Train Acc: 96.3668\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01412\n",
      "Average Test Loss: 0.3105; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[191/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0103\n",
      "Average Train Loss: 0.0935; Train Acc: 96.5172\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01187\n",
      "Average Test Loss: 0.2997; Test Acc: 90.5286\n",
      "-------------------------------------------\n",
      "Epoch:[192/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0417\n",
      "Average Train Loss: 0.0993; Train Acc: 96.1413\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01291\n",
      "Average Test Loss: 0.3050; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[193/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1950\n",
      "Average Train Loss: 0.0965; Train Acc: 96.3418\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01430\n",
      "Average Test Loss: 0.3002; Test Acc: 90.7489\n",
      "-------------------------------------------\n",
      "Epoch:[194/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0814\n",
      "Average Train Loss: 0.1030; Train Acc: 96.1413\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01319\n",
      "Average Test Loss: 0.3056; Test Acc: 90.3084\n",
      "-------------------------------------------\n",
      "Epoch:[195/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1541\n",
      "Average Train Loss: 0.1017; Train Acc: 96.3668\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.00969\n",
      "Average Test Loss: 0.3149; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[196/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0262\n",
      "Average Train Loss: 0.1033; Train Acc: 96.0912\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01549\n",
      "Average Test Loss: 0.3065; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[197/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0290\n",
      "Average Train Loss: 0.1010; Train Acc: 96.1914\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01153\n",
      "Average Test Loss: 0.3019; Test Acc: 90.1982\n",
      "-------------------------------------------\n",
      "Epoch:[198/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0574\n",
      "Average Train Loss: 0.0941; Train Acc: 96.5923\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01422\n",
      "Average Test Loss: 0.3166; Test Acc: 90.0881\n",
      "-------------------------------------------\n",
      "Epoch:[199/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.1728\n",
      "Average Train Loss: 0.0945; Train Acc: 96.3418\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01408\n",
      "Average Test Loss: 0.3076; Test Acc: 89.8678\n",
      "-------------------------------------------\n",
      "Epoch:[200/200]\n",
      "Training...\n",
      "Iter: [125/125] Loss: 0.0217\n",
      "Average Train Loss: 0.0957; Train Acc: 96.3167\n",
      "\n",
      "Testing...\n",
      "Iter: [908/908] Loss: 0.01720\n",
      "Average Test Loss: 0.3020; Test Acc: 90.0881\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "network = Classification(10, alignment=True).cuda()\n",
    "epochs = 200 # you can change the value to a small number for debugging\n",
    "\n",
    "## TASK 2.8\n",
    "# see Appendix C\n",
    "# choose an optimizer and an initial learning rate\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08,\n",
    "            weight_decay=1e-4)\n",
    "# choose a lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "#######3\n",
    "\n",
    "# start training\n",
    "train_cls(train_cls_loader, test_cls_loader, network, optimizer, epochs, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the best test accuracy you can get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best test accuracy is 90.7489."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Segmentation Network\n",
    "In this network, you will use the global features and local features generated by the `Feature` network defined above.\n",
    "\n",
    "The global feature matrix is of size `B x 1024` and the local feature matrix is of size `B x 64 x N`.\n",
    "\n",
    "They need to be stacked together to a new matrix of size `B x 1088 x n` (How?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main train function for classification\n",
    "class Segmentation(nn.Module):\n",
    "    def __init__(self, num_classes, alignment=False):\n",
    "        super(Segmentation, self).__init__()\n",
    "        \n",
    "        self.feature = Feature(alignment=alignment)\n",
    "        \n",
    "        ## TASK 2.9\n",
    "        ## shared mlp\n",
    "        ## input size: B x 1088 x N\n",
    "        ## output size: B x num_classes x N\n",
    "        self.seg_layers = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv1d(1088,512,1)),\n",
    "          ('bn1', nn.BatchNorm1d(512)),  \n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv1d(512,256,1)),\n",
    "          ('bn2', nn.BatchNorm1d(256)),  \n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('conv3', nn.Conv1d(256,128,1)),\n",
    "          ('bn3', nn.BatchNorm1d(128)),  \n",
    "          ('relu3', nn.ReLU()),\n",
    "          ('conv4', nn.Conv1d(128,num_classes,1))         \n",
    "        ])) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        g, l, trans = self.feature(x)\n",
    "        \n",
    "        ## TASK 2.10\n",
    "        # concat global features and local features to a single matrix\n",
    "        # g - B x 1024, global features\n",
    "        # l - B x 64 x N, local features\n",
    "        # x - B x 1088 x N, concatenated features\n",
    "        B,_,N = l.shape\n",
    "        # expand = out_max.view(-1, 2048+16, 1).repeat(1, 1, x.size)\n",
    "        g = g.view(B,1024,1).expand([B,1024,N])\n",
    "        x = torch.cat([g,l],dim=1)\n",
    "        \n",
    "        ## TASK 2.9\n",
    "        ## forward of shared mlp\n",
    "        # input - B x 1088 x N\n",
    "        # output - B x num_classes x N  \n",
    "        x = self.seg_layers(x)\n",
    "        \n",
    "        return x, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation(\n",
      "  (feature): Feature(\n",
      "    (input_transform): Transformation(\n",
      "      (shared_mlp): Sequential(\n",
      "        (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU()\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (local_sharedmlp): Sequential(\n",
      "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (feature_transform): Transformation(\n",
      "      (shared_mlp): Sequential(\n",
      "        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU()\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (global_sharedmlp): Sequential(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (seg_layers): Sequential(\n",
      "    (conv1): Conv1d(1088, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (conv4): Conv1d(128, 5, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "S = Segmentation(5, True).cuda()\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 4.0678e-01,  3.3083e-01,  4.8476e-01,  ...,  5.5892e-01,\n",
      "           2.5157e-01,  4.2127e-01],\n",
      "         [ 2.7037e-01,  2.1058e-01,  3.6191e-01,  ...,  2.3889e-01,\n",
      "          -1.9467e-01,  1.0230e-01],\n",
      "         [-1.9216e-01, -7.6937e-02, -1.5251e-01,  ..., -5.5411e-03,\n",
      "          -3.5494e-04, -1.2999e-01],\n",
      "         [ 7.2277e-01,  6.9677e-01,  6.7076e-01,  ...,  4.4341e-01,\n",
      "           7.9080e-01,  2.9861e-01],\n",
      "         [ 1.2703e-01, -2.6921e-01,  8.4761e-02,  ...,  3.9022e-01,\n",
      "           3.4498e-02,  4.7865e-01]],\n",
      "\n",
      "        [[-2.5109e-01, -4.8191e-01,  6.0220e-02,  ..., -3.5375e-01,\n",
      "          -3.2851e-01, -4.7964e-01],\n",
      "         [ 1.6387e-01,  1.7673e-01, -9.4886e-02,  ...,  3.4510e-01,\n",
      "           2.3036e-01,  2.8644e-01],\n",
      "         [ 6.8194e-02, -5.8677e-02, -1.9294e-01,  ..., -5.4642e-02,\n",
      "          -9.5231e-02,  6.8759e-02],\n",
      "         [ 1.4040e-01,  1.9371e-01,  3.2248e-01,  ..., -2.6951e-01,\n",
      "           8.0368e-02, -7.2421e-02],\n",
      "         [-1.7834e-01,  1.3822e-01,  2.1928e-01,  ..., -1.9802e-01,\n",
      "          -2.1088e-01, -1.6975e-01]],\n",
      "\n",
      "        [[ 1.3677e-01,  2.5546e-01,  2.5621e-01,  ...,  2.2728e-01,\n",
      "           4.8148e-01,  4.0484e-01],\n",
      "         [ 1.7501e-02, -2.5521e-01, -2.0937e-01,  ..., -7.7884e-02,\n",
      "          -1.4364e-01, -1.4779e-01],\n",
      "         [-4.4358e-01, -3.3113e-01, -2.7912e-01,  ..., -1.8782e-02,\n",
      "          -3.0218e-01, -4.3614e-02],\n",
      "         [ 1.0568e-02,  3.7127e-01,  1.1089e-01,  ...,  3.8792e-01,\n",
      "           3.9139e-01,  2.3537e-01],\n",
      "         [-4.8518e-01, -8.6439e-01, -4.1170e-01,  ..., -5.6199e-01,\n",
      "          -1.6911e-01, -6.0791e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.6445e-01,  1.6191e-01,  3.4151e-01,  ...,  2.5793e-01,\n",
      "           3.0506e-01,  8.9402e-02],\n",
      "         [-2.3390e-01, -2.2052e-01, -1.0640e-01,  ..., -1.2263e-01,\n",
      "          -1.5592e-01, -6.3855e-02],\n",
      "         [-9.8905e-02,  2.5266e-02, -1.5166e-01,  ..., -1.4651e-01,\n",
      "           1.5053e-02, -2.6117e-01],\n",
      "         [ 2.8760e-01,  1.2945e-01,  2.3549e-01,  ...,  2.4886e-01,\n",
      "           1.5040e-01,  4.5437e-01],\n",
      "         [ 2.2896e-02, -4.0551e-01, -2.6557e-01,  ..., -3.9537e-03,\n",
      "          -4.1808e-01, -1.4554e-01]],\n",
      "\n",
      "        [[-1.9046e-01,  1.0951e-01, -2.2795e-01,  ..., -1.2319e-01,\n",
      "          -4.5593e-02, -2.6542e-01],\n",
      "         [ 3.2727e-02,  3.6345e-01, -2.6480e-02,  ..., -7.0141e-02,\n",
      "          -3.1982e-02, -9.3541e-03],\n",
      "         [-4.4094e-01, -6.9931e-01, -5.2857e-01,  ..., -4.1265e-01,\n",
      "          -2.4292e-01, -4.2705e-01],\n",
      "         [ 5.1159e-01,  9.4498e-01,  7.7189e-01,  ...,  5.2149e-01,\n",
      "           3.8432e-01,  4.9427e-01],\n",
      "         [ 2.3969e-02, -9.8768e-02, -4.0015e-01,  ...,  1.3385e-02,\n",
      "           3.4281e-02,  3.6902e-02]],\n",
      "\n",
      "        [[ 2.5848e-01,  2.2196e-01,  2.7980e-01,  ...,  5.0152e-01,\n",
      "           5.4416e-01,  2.6266e-01],\n",
      "         [ 7.3207e-02,  4.4641e-02,  2.3188e-02,  ...,  1.0204e-01,\n",
      "           1.0161e-02,  5.3690e-02],\n",
      "         [ 8.8168e-02,  1.3274e-01,  7.9904e-02,  ...,  9.4427e-02,\n",
      "           5.5873e-02, -1.4655e-02],\n",
      "         [ 3.5618e-01,  4.6138e-01,  4.4956e-01,  ...,  3.2985e-01,\n",
      "           5.2346e-01,  3.7862e-01],\n",
      "         [ 3.4335e-02, -3.1086e-02, -3.2657e-02,  ...,  2.2236e-01,\n",
      "           1.2859e-01, -8.6354e-02]]], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>), tensor([[[ 0.6672, -0.0709, -0.0945,  ..., -0.2281,  0.1234, -0.8866],\n",
      "         [ 0.3960,  1.0104,  0.1624,  ...,  0.0720,  0.1458, -0.0369],\n",
      "         [ 0.2073,  0.7817,  1.1082,  ...,  0.3023,  0.4869,  0.7842],\n",
      "         ...,\n",
      "         [ 0.1233, -0.6519,  0.3090,  ...,  0.7933, -0.6789,  0.2499],\n",
      "         [ 0.6646, -0.3393,  0.3264,  ...,  0.0856,  0.3885, -0.1912],\n",
      "         [-0.2313,  0.7034, -1.0470,  ...,  0.1678, -0.1983,  1.0697]],\n",
      "\n",
      "        [[ 1.1235, -0.1911,  0.0286,  ...,  0.1416,  0.1003, -0.7090],\n",
      "         [ 0.0343,  1.0425,  0.5982,  ..., -0.0795,  0.4840,  0.4279],\n",
      "         [-0.2868, -0.3089,  0.9989,  ...,  0.1058,  0.0371,  0.4793],\n",
      "         ...,\n",
      "         [ 0.2406, -0.0976, -0.1080,  ...,  0.2577, -0.5552,  0.3178],\n",
      "         [ 0.0765,  0.2602,  0.1839,  ...,  0.6029,  0.6886, -0.4425],\n",
      "         [-0.6713,  0.1318, -0.6567,  ...,  0.0199, -0.4429,  1.3021]],\n",
      "\n",
      "        [[ 1.7819, -0.3460,  0.1569,  ..., -0.1739,  0.6745, -0.1954],\n",
      "         [-0.2604,  0.4965,  0.0125,  ...,  0.2326,  0.2086, -0.5409],\n",
      "         [ 0.6344, -0.0412,  0.8220,  ...,  0.3449,  0.9256,  0.2079],\n",
      "         ...,\n",
      "         [ 0.9211,  0.4276, -0.6828,  ..., -0.4786,  0.1449,  0.5174],\n",
      "         [-0.2847,  0.4569,  0.1160,  ..., -0.0246,  0.5532, -0.2663],\n",
      "         [-0.4865, -0.6777,  0.2673,  ..., -0.1695, -0.6518,  0.8721]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6055,  0.1162, -0.3535,  ..., -0.4520, -0.3587,  0.4786],\n",
      "         [-0.1379,  1.4519, -0.4090,  ...,  0.2985, -0.1831, -0.1949],\n",
      "         [-0.2730,  0.2114,  0.7345,  ..., -0.3529, -0.1131, -0.2412],\n",
      "         ...,\n",
      "         [ 0.1131, -0.2035,  0.0256,  ...,  0.2809,  0.2438,  0.0912],\n",
      "         [ 0.3523,  0.0764,  0.0525,  ..., -0.0901,  1.2623,  0.2482],\n",
      "         [-0.5883, -0.3285, -0.3123,  ..., -0.1077,  0.3003,  0.5911]],\n",
      "\n",
      "        [[ 1.4115,  0.2926, -0.3378,  ..., -0.0221, -0.4192, -0.3043],\n",
      "         [-0.3317,  0.9205,  0.6228,  ...,  0.0630,  0.2679, -0.8922],\n",
      "         [-0.4589,  0.4657,  0.3632,  ..., -0.5284,  0.6047,  0.9980],\n",
      "         ...,\n",
      "         [ 0.6027, -0.2744,  0.6715,  ...,  0.0774,  0.0914,  0.0760],\n",
      "         [ 0.2987,  0.1439,  0.9953,  ..., -0.0169,  1.0146,  0.1770],\n",
      "         [-0.7577,  0.0382,  0.4074,  ..., -0.3327, -0.5774,  1.4180]],\n",
      "\n",
      "        [[ 0.7902, -0.1990, -0.4239,  ...,  0.2418, -0.2202, -0.2673],\n",
      "         [-0.0291,  0.9155, -0.5798,  ...,  0.1991,  0.1598, -0.5338],\n",
      "         [ 0.1768,  0.3757,  1.3199,  ..., -0.0595,  0.4990,  0.3703],\n",
      "         ...,\n",
      "         [ 0.1255, -0.7089, -0.0863,  ...,  0.4376, -0.3305, -0.0402],\n",
      "         [ 0.0420, -0.2604,  0.2681,  ..., -0.1218,  0.7855,  0.2510],\n",
      "         [-0.7645, -0.1699,  0.2116,  ..., -0.8285, -0.3828,  1.1378]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    }
   ],
   "source": [
    "## random generate data and test this network\n",
    "d = torch.randn(10,3,100).cuda()\n",
    "test = S(d)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Calculating Intersection over Union (IoU) \n",
    "For 2D image, the IoU is calculated as follows,\n",
    "![iou](img/iou.png)\n",
    "\n",
    "How is it used in the literature of point clouds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TASK 2.11\n",
    "# implement the helper functions to calculate the IoU\n",
    "def get_i_and_u(pred, target, num_classes):\n",
    "    \"\"\"Calculate intersection and union between pred and target.\n",
    "    pred -- B x N matrix\n",
    "    target -- B x N matrix\n",
    "    num_classes -- number of classes\n",
    "    return i, u\n",
    "    i -- B x N binary matrix, intersection, i[b, n] equals 1 if and only if it is a true-positive.\n",
    "    u -- B x N binary matrix, union, u[b, n] equals 0 if and only if it is a true-negative\n",
    "    \"\"\"\n",
    "    ## TASK 2.11\n",
    "    ## calculate i and u here\n",
    "    ## hint: useful function `F.one_hot`    \n",
    "    ## hint: use element-wise logical tensor operation (`&` and `|`)\n",
    "    p = F.one_hot(pred, num_classes)\n",
    "    t = F.one_hot(target, num_classes)\n",
    "    # i = (p & t).sum(0)\n",
    "    i = (p & t).sum(-1)\n",
    "    #print(i.shape) [32,2048]\n",
    "    u = (p | t ).sum(-1)\n",
    "    \n",
    "    return i, u\n",
    "\n",
    "def get_iou(pred, target, num_classes):\n",
    "    \"\"\"Calculate IoU\n",
    "    pred -- B x N matrix\n",
    "    target -- B x N matrix\n",
    "    num_classes -- number of classes\n",
    "    return iou\n",
    "    iou -- B matrix, iou[b] is the IoU of b-th point cloud in this batch\n",
    "    \"\"\"\n",
    "    ## use the helper function `i_and_u` defined above\n",
    "    i, u = get_i_and_u(pred, target, num_classes)\n",
    "    ## TASK 2.11\n",
    "    ## calculate iou\n",
    "    iou = i.float() / u.float()\n",
    "    #print(iou.shape)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Train this network on ShapeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main train function for segmentation\n",
    "def train_seg(train_loader, test_loader, network, optimizer, epochs, scheduler):  \n",
    "    reg = OrthoLoss()\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch:[{:02d}/{:02d}]'.format(epoch+1, epochs))\n",
    "        print('Training...')\n",
    "        network.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        ious = []\n",
    "        for batch, (pos, label) in enumerate(train_loader):\n",
    "            network.zero_grad()\n",
    "            pos, label = pos.cuda(), label.cuda()\n",
    "            \n",
    "            ## TASK 2.12\n",
    "            ## forward propagation\n",
    "            output, trans = network(pos)\n",
    "            loss = nn.functional.nll_loss(nn.functional.log_softmax(output, dim = 1), label)\n",
    "            ##########\n",
    "            if trans is not None:\n",
    "                loss += reg(trans) * 0.001        \n",
    "\n",
    "            pred = output.max(1)[1]\n",
    "            correct += pred.eq(label).sum().item()\n",
    "            total += label.numel()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            ious += [get_iou(pred, label, train_loader.dataset.num_classes)]\n",
    "            print('\\rIter: [{:03d}/{:03d}] Loss: {:.4f}'.format(batch+1, len(train_loader), loss.item()), end='', flush=True)\n",
    "        \n",
    "        scheduler.step()\n",
    "        print('\\nAverage Train Loss: {:.4f}; Train Acc: {:.4f}; Train mean IoU: {:.4f}'.format(train_loss/len(train_loader), correct/total * 100, torch.cat(ious, dim=0).mean().item()))\n",
    "\n",
    "        print('\\nTesting...')\n",
    "        with torch.no_grad():\n",
    "            network.eval()\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            ious = []\n",
    "            for batch, (pos, label) in enumerate(test_loader):\n",
    "                pos, label = pos.cuda(), label.cuda()\n",
    "                \n",
    "                ## TASK 2.12\n",
    "                ## forward propagation\n",
    "                output, trans = network(pos)\n",
    "                loss = nn.functional.nll_loss(nn.functional.log_softmax(output, dim = 1), label)\n",
    "                ##########\n",
    "                \n",
    "                if trans is not None:\n",
    "                    loss += reg(trans) * 0.001   \n",
    "\n",
    "                pred = output.max(1)[1]\n",
    "                correct += pred.eq(label).sum().item()\n",
    "                total += label.numel()\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                ious += [get_iou(pred, label, train_loader.dataset.num_classes)]\n",
    "                print('\\rIter: [{:03d}/{:03d}] Loss: {:.4f}'.format(batch+1, len(test_loader), loss.item()), end='', flush=True)\n",
    "\n",
    "            print('\\nAverage Test Loss: {:.4f}; Test Acc: {:.4f}; Test mean IoU: {:.4f}'.format(test_loss/len(test_loader), correct/total * 100, torch.cat(ious, dim=0).mean().item()))\n",
    "        print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[01/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.5263\n",
      "Average Train Loss: 0.6830; Train Acc: 76.9861; Train mean IoU: 0.7699\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.5374\n",
      "Average Test Loss: 0.5251; Test Acc: 82.2901; Test mean IoU: 0.8229\n",
      "-------------------------------------------\n",
      "Epoch:[02/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.4487\n",
      "Average Train Loss: 0.3812; Train Acc: 87.3273; Train mean IoU: 0.8733\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.3340\n",
      "Average Test Loss: 0.4339; Test Acc: 84.0112; Test mean IoU: 0.8401\n",
      "-------------------------------------------\n",
      "Epoch:[03/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.3557\n",
      "Average Train Loss: 0.3299; Train Acc: 88.6881; Train mean IoU: 0.8869\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.3667\n",
      "Average Test Loss: 0.4137; Test Acc: 84.8100; Test mean IoU: 0.8481\n",
      "-------------------------------------------\n",
      "Epoch:[04/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2502\n",
      "Average Train Loss: 0.2986; Train Acc: 89.3741; Train mean IoU: 0.8937\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2880\n",
      "Average Test Loss: 0.3432; Test Acc: 87.5680; Test mean IoU: 0.8757\n",
      "-------------------------------------------\n",
      "Epoch:[05/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.3068\n",
      "Average Train Loss: 0.2818; Train Acc: 89.7730; Train mean IoU: 0.8977\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2508\n",
      "Average Test Loss: 0.3253; Test Acc: 88.3325; Test mean IoU: 0.8833\n",
      "-------------------------------------------\n",
      "Epoch:[06/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.4322\n",
      "Average Train Loss: 0.2747; Train Acc: 90.0081; Train mean IoU: 0.9001\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2340\n",
      "Average Test Loss: 0.3862; Test Acc: 86.4629; Test mean IoU: 0.8646\n",
      "-------------------------------------------\n",
      "Epoch:[07/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.3569\n",
      "Average Train Loss: 0.2785; Train Acc: 89.8629; Train mean IoU: 0.8986\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2486\n",
      "Average Test Loss: 0.3009; Test Acc: 88.6816; Test mean IoU: 0.8868\n",
      "-------------------------------------------\n",
      "Epoch:[08/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2519\n",
      "Average Train Loss: 0.2591; Train Acc: 90.3707; Train mean IoU: 0.9037\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2308\n",
      "Average Test Loss: 0.3385; Test Acc: 87.6064; Test mean IoU: 0.8761\n",
      "-------------------------------------------\n",
      "Epoch:[09/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.5045\n",
      "Average Train Loss: 0.2567; Train Acc: 90.3852; Train mean IoU: 0.9039\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.3401\n",
      "Average Test Loss: 0.3828; Test Acc: 85.9669; Test mean IoU: 0.8597\n",
      "-------------------------------------------\n",
      "Epoch:[10/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2061\n",
      "Average Train Loss: 0.2688; Train Acc: 89.9913; Train mean IoU: 0.8999\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.7500\n",
      "Average Test Loss: 0.4387; Test Acc: 82.6832; Test mean IoU: 0.8268\n",
      "-------------------------------------------\n",
      "Epoch:[11/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.3213\n",
      "Average Train Loss: 0.2514; Train Acc: 90.4052; Train mean IoU: 0.9041\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2706\n",
      "Average Test Loss: 0.3781; Test Acc: 85.9895; Test mean IoU: 0.8599\n",
      "-------------------------------------------\n",
      "Epoch:[12/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.3352\n",
      "Average Train Loss: 0.2350; Train Acc: 90.9825; Train mean IoU: 0.9098\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2137\n",
      "Average Test Loss: 0.3198; Test Acc: 87.5325; Test mean IoU: 0.8753\n",
      "-------------------------------------------\n",
      "Epoch:[13/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.3623\n",
      "Average Train Loss: 0.2460; Train Acc: 90.7005; Train mean IoU: 0.9070\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2642\n",
      "Average Test Loss: 0.3316; Test Acc: 87.2802; Test mean IoU: 0.8728\n",
      "-------------------------------------------\n",
      "Epoch:[14/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2470\n",
      "Average Train Loss: 0.2292; Train Acc: 91.1863; Train mean IoU: 0.9119\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.5610\n",
      "Average Test Loss: 0.3947; Test Acc: 84.5421; Test mean IoU: 0.8454\n",
      "-------------------------------------------\n",
      "Epoch:[15/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.4024\n",
      "Average Train Loss: 0.2194; Train Acc: 91.5629; Train mean IoU: 0.9156\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.4257\n",
      "Average Test Loss: 0.3758; Test Acc: 85.3395; Test mean IoU: 0.8534\n",
      "-------------------------------------------\n",
      "Epoch:[16/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1977\n",
      "Average Train Loss: 0.2158; Train Acc: 91.5776; Train mean IoU: 0.9158\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.3314\n",
      "Average Test Loss: 0.4105; Test Acc: 85.0855; Test mean IoU: 0.8509\n",
      "-------------------------------------------\n",
      "Epoch:[17/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1999\n",
      "Average Train Loss: 0.2098; Train Acc: 91.7731; Train mean IoU: 0.9177\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1549\n",
      "Average Test Loss: 0.2890; Test Acc: 89.2867; Test mean IoU: 0.8929\n",
      "-------------------------------------------\n",
      "Epoch:[18/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2502\n",
      "Average Train Loss: 0.2133; Train Acc: 91.6741; Train mean IoU: 0.9167\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2334\n",
      "Average Test Loss: 0.2856; Test Acc: 88.7672; Test mean IoU: 0.8877\n",
      "-------------------------------------------\n",
      "Epoch:[19/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1982\n",
      "Average Train Loss: 0.2067; Train Acc: 91.8875; Train mean IoU: 0.9189\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2080\n",
      "Average Test Loss: 0.2892; Test Acc: 89.1026; Test mean IoU: 0.8910\n",
      "-------------------------------------------\n",
      "Epoch:[20/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1800\n",
      "Average Train Loss: 0.1998; Train Acc: 92.1760; Train mean IoU: 0.9218\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.3771\n",
      "Average Test Loss: 0.2871; Test Acc: 88.8407; Test mean IoU: 0.8884\n",
      "-------------------------------------------\n",
      "Epoch:[21/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2354\n",
      "Average Train Loss: 0.1882; Train Acc: 92.6011; Train mean IoU: 0.9260\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2785\n",
      "Average Test Loss: 0.2557; Test Acc: 90.1482; Test mean IoU: 0.9015\n",
      "-------------------------------------------\n",
      "Epoch:[22/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2050\n",
      "Average Train Loss: 0.1846; Train Acc: 92.7553; Train mean IoU: 0.9276\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2028\n",
      "Average Test Loss: 0.2749; Test Acc: 89.9708; Test mean IoU: 0.8997\n",
      "-------------------------------------------\n",
      "Epoch:[23/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1504\n",
      "Average Train Loss: 0.1795; Train Acc: 92.9366; Train mean IoU: 0.9294\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2417\n",
      "Average Test Loss: 0.3190; Test Acc: 87.9637; Test mean IoU: 0.8796\n",
      "-------------------------------------------\n",
      "Epoch:[24/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1743\n",
      "Average Train Loss: 0.1806; Train Acc: 92.8897; Train mean IoU: 0.9289\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2059\n",
      "Average Test Loss: 0.2751; Test Acc: 89.8866; Test mean IoU: 0.8989\n",
      "-------------------------------------------\n",
      "Epoch:[25/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1788\n",
      "Average Train Loss: 0.1739; Train Acc: 93.1739; Train mean IoU: 0.9317\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2704\n",
      "Average Test Loss: 0.2743; Test Acc: 89.1181; Test mean IoU: 0.8912\n",
      "-------------------------------------------\n",
      "Epoch:[26/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2724\n",
      "Average Train Loss: 0.1722; Train Acc: 93.2683; Train mean IoU: 0.9327\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.3038\n",
      "Average Test Loss: 0.2986; Test Acc: 88.9071; Test mean IoU: 0.8891\n",
      "-------------------------------------------\n",
      "Epoch:[27/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1623\n",
      "Average Train Loss: 0.1852; Train Acc: 92.6968; Train mean IoU: 0.9270\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1945\n",
      "Average Test Loss: 0.2984; Test Acc: 88.7057; Test mean IoU: 0.8871\n",
      "-------------------------------------------\n",
      "Epoch:[28/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1952\n",
      "Average Train Loss: 0.1788; Train Acc: 92.9688; Train mean IoU: 0.9297\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1946\n",
      "Average Test Loss: 0.2803; Test Acc: 89.5272; Test mean IoU: 0.8953\n",
      "-------------------------------------------\n",
      "Epoch:[29/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1588\n",
      "Average Train Loss: 0.1724; Train Acc: 93.2039; Train mean IoU: 0.9320\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1944\n",
      "Average Test Loss: 0.2967; Test Acc: 88.6203; Test mean IoU: 0.8862\n",
      "-------------------------------------------\n",
      "Epoch:[30/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2077\n",
      "Average Train Loss: 0.1682; Train Acc: 93.4158; Train mean IoU: 0.9342\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2582\n",
      "Average Test Loss: 0.2687; Test Acc: 89.4531; Test mean IoU: 0.8945\n",
      "-------------------------------------------\n",
      "Epoch:[31/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1416\n",
      "Average Train Loss: 0.1661; Train Acc: 93.4317; Train mean IoU: 0.9343\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2260\n",
      "Average Test Loss: 0.3230; Test Acc: 88.6072; Test mean IoU: 0.8861\n",
      "-------------------------------------------\n",
      "Epoch:[32/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1652\n",
      "Average Train Loss: 0.1642; Train Acc: 93.5073; Train mean IoU: 0.9351\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1830\n",
      "Average Test Loss: 0.2845; Test Acc: 89.1377; Test mean IoU: 0.8914\n",
      "-------------------------------------------\n",
      "Epoch:[33/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2083\n",
      "Average Train Loss: 0.1627; Train Acc: 93.5839; Train mean IoU: 0.9358\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2046\n",
      "Average Test Loss: 0.2923; Test Acc: 89.2212; Test mean IoU: 0.8922\n",
      "-------------------------------------------\n",
      "Epoch:[34/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1455\n",
      "Average Train Loss: 0.1664; Train Acc: 93.4133; Train mean IoU: 0.9341\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1609\n",
      "Average Test Loss: 0.2876; Test Acc: 89.5001; Test mean IoU: 0.8950\n",
      "-------------------------------------------\n",
      "Epoch:[35/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1319\n",
      "Average Train Loss: 0.1587; Train Acc: 93.7510; Train mean IoU: 0.9375\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1989\n",
      "Average Test Loss: 0.2793; Test Acc: 89.7941; Test mean IoU: 0.8979\n",
      "-------------------------------------------\n",
      "Epoch:[36/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2667\n",
      "Average Train Loss: 0.1601; Train Acc: 93.6753; Train mean IoU: 0.9368\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2563\n",
      "Average Test Loss: 0.3381; Test Acc: 87.8344; Test mean IoU: 0.8783\n",
      "-------------------------------------------\n",
      "Epoch:[37/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1605\n",
      "Average Train Loss: 0.1586; Train Acc: 93.7563; Train mean IoU: 0.9376\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1180\n",
      "Average Test Loss: 0.2753; Test Acc: 89.9089; Test mean IoU: 0.8991\n",
      "-------------------------------------------\n",
      "Epoch:[38/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1539\n",
      "Average Train Loss: 0.1538; Train Acc: 93.9223; Train mean IoU: 0.9392\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2424\n",
      "Average Test Loss: 0.3198; Test Acc: 88.6039; Test mean IoU: 0.8860\n",
      "-------------------------------------------\n",
      "Epoch:[39/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1738\n",
      "Average Train Loss: 0.1508; Train Acc: 94.0402; Train mean IoU: 0.9404\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2256\n",
      "Average Test Loss: 0.3931; Test Acc: 85.9583; Test mean IoU: 0.8596\n",
      "-------------------------------------------\n",
      "Epoch:[40/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2544\n",
      "Average Train Loss: 0.1551; Train Acc: 93.9742; Train mean IoU: 0.9397\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2386\n",
      "Average Test Loss: 0.3000; Test Acc: 88.7664; Test mean IoU: 0.8877\n",
      "-------------------------------------------\n",
      "Epoch:[41/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2274\n",
      "Average Train Loss: 0.1449; Train Acc: 94.3349; Train mean IoU: 0.9433\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2389\n",
      "Average Test Loss: 0.2512; Test Acc: 90.7146; Test mean IoU: 0.9071\n",
      "-------------------------------------------\n",
      "Epoch:[42/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2022\n",
      "Average Train Loss: 0.1451; Train Acc: 94.2749; Train mean IoU: 0.9427\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1302\n",
      "Average Test Loss: 0.2536; Test Acc: 90.8668; Test mean IoU: 0.9087\n",
      "-------------------------------------------\n",
      "Epoch:[43/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1495\n",
      "Average Train Loss: 0.1370; Train Acc: 94.6129; Train mean IoU: 0.9461\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1409\n",
      "Average Test Loss: 0.2447; Test Acc: 91.5016; Test mean IoU: 0.9150\n",
      "-------------------------------------------\n",
      "Epoch:[44/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1432\n",
      "Average Train Loss: 0.1346; Train Acc: 94.6839; Train mean IoU: 0.9468\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2199\n",
      "Average Test Loss: 0.2505; Test Acc: 90.9847; Test mean IoU: 0.9098\n",
      "-------------------------------------------\n",
      "Epoch:[45/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1613\n",
      "Average Train Loss: 0.1319; Train Acc: 94.8047; Train mean IoU: 0.9480\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2695\n",
      "Average Test Loss: 0.2576; Test Acc: 91.0297; Test mean IoU: 0.9103\n",
      "-------------------------------------------\n",
      "Epoch:[46/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2068\n",
      "Average Train Loss: 0.1321; Train Acc: 94.8075; Train mean IoU: 0.9481\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1734\n",
      "Average Test Loss: 0.2958; Test Acc: 89.6275; Test mean IoU: 0.8963\n",
      "-------------------------------------------\n",
      "Epoch:[47/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1738\n",
      "Average Train Loss: 0.1311; Train Acc: 94.8300; Train mean IoU: 0.9483\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1746\n",
      "Average Test Loss: 0.2718; Test Acc: 90.3081; Test mean IoU: 0.9031\n",
      "-------------------------------------------\n",
      "Epoch:[48/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1418\n",
      "Average Train Loss: 0.1286; Train Acc: 94.8962; Train mean IoU: 0.9490\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.3759\n",
      "Average Test Loss: 0.2904; Test Acc: 89.5284; Test mean IoU: 0.8953\n",
      "-------------------------------------------\n",
      "Epoch:[49/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1565\n",
      "Average Train Loss: 0.1287; Train Acc: 94.9235; Train mean IoU: 0.9492\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1633\n",
      "Average Test Loss: 0.2536; Test Acc: 91.3491; Test mean IoU: 0.9135\n",
      "-------------------------------------------\n",
      "Epoch:[50/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1302\n",
      "Average Train Loss: 0.1303; Train Acc: 94.8343; Train mean IoU: 0.9483\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1170\n",
      "Average Test Loss: 0.2674; Test Acc: 90.8819; Test mean IoU: 0.9088\n",
      "-------------------------------------------\n",
      "Epoch:[51/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1639\n",
      "Average Train Loss: 0.1301; Train Acc: 94.8499; Train mean IoU: 0.9485\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2922\n",
      "Average Test Loss: 0.2656; Test Acc: 90.8013; Test mean IoU: 0.9080\n",
      "-------------------------------------------\n",
      "Epoch:[52/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1306\n",
      "Average Train Loss: 0.1265; Train Acc: 94.9843; Train mean IoU: 0.9498\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1573\n",
      "Average Test Loss: 0.2614; Test Acc: 90.9657; Test mean IoU: 0.9097\n",
      "-------------------------------------------\n",
      "Epoch:[53/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0965\n",
      "Average Train Loss: 0.1259; Train Acc: 94.9890; Train mean IoU: 0.9499\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1738\n",
      "Average Test Loss: 0.2660; Test Acc: 90.7559; Test mean IoU: 0.9076\n",
      "-------------------------------------------\n",
      "Epoch:[54/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1327\n",
      "Average Train Loss: 0.1242; Train Acc: 95.0553; Train mean IoU: 0.9506\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2369\n",
      "Average Test Loss: 0.2940; Test Acc: 89.5296; Test mean IoU: 0.8953\n",
      "-------------------------------------------\n",
      "Epoch:[55/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1685\n",
      "Average Train Loss: 0.1269; Train Acc: 94.9605; Train mean IoU: 0.9496\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2534\n",
      "Average Test Loss: 0.2677; Test Acc: 90.8945; Test mean IoU: 0.9089\n",
      "-------------------------------------------\n",
      "Epoch:[56/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1329\n",
      "Average Train Loss: 0.1257; Train Acc: 95.0022; Train mean IoU: 0.9500\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1593\n",
      "Average Test Loss: 0.2686; Test Acc: 90.9449; Test mean IoU: 0.9094\n",
      "-------------------------------------------\n",
      "Epoch:[57/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1978\n",
      "Average Train Loss: 0.1238; Train Acc: 95.1027; Train mean IoU: 0.9510\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1722\n",
      "Average Test Loss: 0.2835; Test Acc: 90.7388; Test mean IoU: 0.9074\n",
      "-------------------------------------------\n",
      "Epoch:[58/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1232\n",
      "Average Train Loss: 0.1281; Train Acc: 94.9215; Train mean IoU: 0.9492\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1291\n",
      "Average Test Loss: 0.2873; Test Acc: 90.4240; Test mean IoU: 0.9042\n",
      "-------------------------------------------\n",
      "Epoch:[59/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1870\n",
      "Average Train Loss: 0.1257; Train Acc: 95.0158; Train mean IoU: 0.9502\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1367\n",
      "Average Test Loss: 0.2921; Test Acc: 90.0528; Test mean IoU: 0.9005\n",
      "-------------------------------------------\n",
      "Epoch:[60/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1982\n",
      "Average Train Loss: 0.1319; Train Acc: 94.7800; Train mean IoU: 0.9478\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1359\n",
      "Average Test Loss: 0.2742; Test Acc: 90.3041; Test mean IoU: 0.9030\n",
      "-------------------------------------------\n",
      "Epoch:[61/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1458\n",
      "Average Train Loss: 0.1185; Train Acc: 95.2833; Train mean IoU: 0.9528\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1667\n",
      "Average Test Loss: 0.2811; Test Acc: 90.5707; Test mean IoU: 0.9057\n",
      "-------------------------------------------\n",
      "Epoch:[62/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1602\n",
      "Average Train Loss: 0.1150; Train Acc: 95.4280; Train mean IoU: 0.9543\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1155\n",
      "Average Test Loss: 0.2659; Test Acc: 91.1003; Test mean IoU: 0.9110\n",
      "-------------------------------------------\n",
      "Epoch:[63/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1620\n",
      "Average Train Loss: 0.1122; Train Acc: 95.5358; Train mean IoU: 0.9554\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1191\n",
      "Average Test Loss: 0.2639; Test Acc: 91.4239; Test mean IoU: 0.9142\n",
      "-------------------------------------------\n",
      "Epoch:[64/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1123\n",
      "Average Train Loss: 0.1098; Train Acc: 95.6283; Train mean IoU: 0.9563\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1531\n",
      "Average Test Loss: 0.2689; Test Acc: 91.1928; Test mean IoU: 0.9119\n",
      "-------------------------------------------\n",
      "Epoch:[65/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0988\n",
      "Average Train Loss: 0.1095; Train Acc: 95.6026; Train mean IoU: 0.9560\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1940\n",
      "Average Test Loss: 0.2749; Test Acc: 91.4249; Test mean IoU: 0.9142\n",
      "-------------------------------------------\n",
      "Epoch:[66/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1380\n",
      "Average Train Loss: 0.1103; Train Acc: 95.5663; Train mean IoU: 0.9557\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1543\n",
      "Average Test Loss: 0.2715; Test Acc: 91.4067; Test mean IoU: 0.9141\n",
      "-------------------------------------------\n",
      "Epoch:[67/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1363\n",
      "Average Train Loss: 0.1084; Train Acc: 95.6489; Train mean IoU: 0.9565\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2242\n",
      "Average Test Loss: 0.2845; Test Acc: 90.9138; Test mean IoU: 0.9091\n",
      "-------------------------------------------\n",
      "Epoch:[68/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1259\n",
      "Average Train Loss: 0.1074; Train Acc: 95.7148; Train mean IoU: 0.9571\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2058\n",
      "Average Test Loss: 0.2803; Test Acc: 91.0781; Test mean IoU: 0.9108\n",
      "-------------------------------------------\n",
      "Epoch:[69/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1816\n",
      "Average Train Loss: 0.1082; Train Acc: 95.7139; Train mean IoU: 0.9571\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2406\n",
      "Average Test Loss: 0.2820; Test Acc: 91.0738; Test mean IoU: 0.9107\n",
      "-------------------------------------------\n",
      "Epoch:[70/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1079\n",
      "Average Train Loss: 0.1095; Train Acc: 95.5940; Train mean IoU: 0.9559\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.0981\n",
      "Average Test Loss: 0.2768; Test Acc: 91.2851; Test mean IoU: 0.9129\n",
      "-------------------------------------------\n",
      "Epoch:[71/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1163\n",
      "Average Train Loss: 0.1060; Train Acc: 95.7519; Train mean IoU: 0.9575\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2289\n",
      "Average Test Loss: 0.2926; Test Acc: 91.0657; Test mean IoU: 0.9107\n",
      "-------------------------------------------\n",
      "Epoch:[72/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1129\n",
      "Average Train Loss: 0.1061; Train Acc: 95.7406; Train mean IoU: 0.9574\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1456\n",
      "Average Test Loss: 0.2935; Test Acc: 90.7457; Test mean IoU: 0.9075\n",
      "-------------------------------------------\n",
      "Epoch:[73/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1279\n",
      "Average Train Loss: 0.1037; Train Acc: 95.8463; Train mean IoU: 0.9585\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1246\n",
      "Average Test Loss: 0.2876; Test Acc: 91.2407; Test mean IoU: 0.9124\n",
      "-------------------------------------------\n",
      "Epoch:[74/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1384\n",
      "Average Train Loss: 0.1046; Train Acc: 95.8045; Train mean IoU: 0.9580\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1238\n",
      "Average Test Loss: 0.2957; Test Acc: 90.8776; Test mean IoU: 0.9088\n",
      "-------------------------------------------\n",
      "Epoch:[75/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1732\n",
      "Average Train Loss: 0.1058; Train Acc: 95.7641; Train mean IoU: 0.9576\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2770\n",
      "Average Test Loss: 0.3064; Test Acc: 89.7912; Test mean IoU: 0.8979\n",
      "-------------------------------------------\n",
      "Epoch:[76/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1080\n",
      "Average Train Loss: 0.1034; Train Acc: 95.8377; Train mean IoU: 0.9584\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1321\n",
      "Average Test Loss: 0.2858; Test Acc: 90.9777; Test mean IoU: 0.9098\n",
      "-------------------------------------------\n",
      "Epoch:[77/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1449\n",
      "Average Train Loss: 0.1043; Train Acc: 95.8180; Train mean IoU: 0.9582\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1537\n",
      "Average Test Loss: 0.2814; Test Acc: 91.1130; Test mean IoU: 0.9111\n",
      "-------------------------------------------\n",
      "Epoch:[78/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1087\n",
      "Average Train Loss: 0.1026; Train Acc: 95.8744; Train mean IoU: 0.9587\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1784\n",
      "Average Test Loss: 0.2799; Test Acc: 91.1116; Test mean IoU: 0.9111\n",
      "-------------------------------------------\n",
      "Epoch:[79/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1348\n",
      "Average Train Loss: 0.1017; Train Acc: 95.9055; Train mean IoU: 0.9591\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1203\n",
      "Average Test Loss: 0.2868; Test Acc: 91.1867; Test mean IoU: 0.9119\n",
      "-------------------------------------------\n",
      "Epoch:[80/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1758\n",
      "Average Train Loss: 0.1042; Train Acc: 95.8354; Train mean IoU: 0.9584\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1469\n",
      "Average Test Loss: 0.2839; Test Acc: 90.7741; Test mean IoU: 0.9077\n",
      "-------------------------------------------\n",
      "Epoch:[81/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1199\n",
      "Average Train Loss: 0.0991; Train Acc: 96.0241; Train mean IoU: 0.9602\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1183\n",
      "Average Test Loss: 0.2786; Test Acc: 91.4846; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[82/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1168\n",
      "Average Train Loss: 0.0963; Train Acc: 96.1474; Train mean IoU: 0.9615\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1666\n",
      "Average Test Loss: 0.2847; Test Acc: 91.4754; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[83/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0973\n",
      "Average Train Loss: 0.0956; Train Acc: 96.1664; Train mean IoU: 0.9617\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1481\n",
      "Average Test Loss: 0.2925; Test Acc: 91.2170; Test mean IoU: 0.9122\n",
      "-------------------------------------------\n",
      "Epoch:[84/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0999\n",
      "Average Train Loss: 0.0940; Train Acc: 96.2213; Train mean IoU: 0.9622\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1634\n",
      "Average Test Loss: 0.2861; Test Acc: 91.5798; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[85/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1048\n",
      "Average Train Loss: 0.0947; Train Acc: 96.1822; Train mean IoU: 0.9618\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1735\n",
      "Average Test Loss: 0.2965; Test Acc: 91.2270; Test mean IoU: 0.9123\n",
      "-------------------------------------------\n",
      "Epoch:[86/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0806\n",
      "Average Train Loss: 0.0927; Train Acc: 96.2533; Train mean IoU: 0.9625\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1398\n",
      "Average Test Loss: 0.3007; Test Acc: 91.5739; Test mean IoU: 0.9157\n",
      "-------------------------------------------\n",
      "Epoch:[87/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1070\n",
      "Average Train Loss: 0.0931; Train Acc: 96.2397; Train mean IoU: 0.9624\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1347\n",
      "Average Test Loss: 0.2901; Test Acc: 91.3630; Test mean IoU: 0.9136\n",
      "-------------------------------------------\n",
      "Epoch:[88/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1275\n",
      "Average Train Loss: 0.0930; Train Acc: 96.2630; Train mean IoU: 0.9626\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1737\n",
      "Average Test Loss: 0.2893; Test Acc: 91.3011; Test mean IoU: 0.9130\n",
      "-------------------------------------------\n",
      "Epoch:[89/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0861\n",
      "Average Train Loss: 0.0931; Train Acc: 96.2365; Train mean IoU: 0.9624\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1318\n",
      "Average Test Loss: 0.2916; Test Acc: 91.2979; Test mean IoU: 0.9130\n",
      "-------------------------------------------\n",
      "Epoch:[90/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1019\n",
      "Average Train Loss: 0.0916; Train Acc: 96.3108; Train mean IoU: 0.9631\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1806\n",
      "Average Test Loss: 0.2960; Test Acc: 91.4960; Test mean IoU: 0.9150\n",
      "-------------------------------------------\n",
      "Epoch:[91/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1238\n",
      "Average Train Loss: 0.0909; Train Acc: 96.3482; Train mean IoU: 0.9635\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1654\n",
      "Average Test Loss: 0.2962; Test Acc: 91.3321; Test mean IoU: 0.9133\n",
      "-------------------------------------------\n",
      "Epoch:[92/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1275\n",
      "Average Train Loss: 0.0918; Train Acc: 96.2991; Train mean IoU: 0.9630\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1317\n",
      "Average Test Loss: 0.2872; Test Acc: 91.5589; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[93/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0918\n",
      "Average Train Loss: 0.0906; Train Acc: 96.3399; Train mean IoU: 0.9634\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1530\n",
      "Average Test Loss: 0.2957; Test Acc: 91.3011; Test mean IoU: 0.9130\n",
      "-------------------------------------------\n",
      "Epoch:[94/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1131\n",
      "Average Train Loss: 0.0913; Train Acc: 96.3133; Train mean IoU: 0.9631\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1268\n",
      "Average Test Loss: 0.2904; Test Acc: 91.5645; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[95/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1645\n",
      "Average Train Loss: 0.0930; Train Acc: 96.2761; Train mean IoU: 0.9628\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1555\n",
      "Average Test Loss: 0.2910; Test Acc: 91.5605; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[96/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0969\n",
      "Average Train Loss: 0.0910; Train Acc: 96.3317; Train mean IoU: 0.9633\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1333\n",
      "Average Test Loss: 0.2969; Test Acc: 91.3899; Test mean IoU: 0.9139\n",
      "-------------------------------------------\n",
      "Epoch:[97/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0862\n",
      "Average Train Loss: 0.0898; Train Acc: 96.3779; Train mean IoU: 0.9638\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1251\n",
      "Average Test Loss: 0.3025; Test Acc: 91.2287; Test mean IoU: 0.9123\n",
      "-------------------------------------------\n",
      "Epoch:[98/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1111\n",
      "Average Train Loss: 0.0896; Train Acc: 96.3947; Train mean IoU: 0.9639\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.2156\n",
      "Average Test Loss: 0.2988; Test Acc: 91.3679; Test mean IoU: 0.9137\n",
      "-------------------------------------------\n",
      "Epoch:[99/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0895\n",
      "Average Train Loss: 0.0887; Train Acc: 96.4190; Train mean IoU: 0.9642\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1177\n",
      "Average Test Loss: 0.3065; Test Acc: 91.0393; Test mean IoU: 0.9104\n",
      "-------------------------------------------\n",
      "Epoch:[100/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1049\n",
      "Average Train Loss: 0.0887; Train Acc: 96.4177; Train mean IoU: 0.9642\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1583\n",
      "Average Test Loss: 0.3068; Test Acc: 91.3180; Test mean IoU: 0.9132\n",
      "-------------------------------------------\n",
      "Epoch:[101/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0753\n",
      "Average Train Loss: 0.0865; Train Acc: 96.5036; Train mean IoU: 0.9650\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1385\n",
      "Average Test Loss: 0.2976; Test Acc: 91.5333; Test mean IoU: 0.9153\n",
      "-------------------------------------------\n",
      "Epoch:[102/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0918\n",
      "Average Train Loss: 0.0857; Train Acc: 96.5463; Train mean IoU: 0.9655\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1331\n",
      "Average Test Loss: 0.2962; Test Acc: 91.5814; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[103/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0858\n",
      "Average Train Loss: 0.0847; Train Acc: 96.5885; Train mean IoU: 0.9659\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1365\n",
      "Average Test Loss: 0.2976; Test Acc: 91.6669; Test mean IoU: 0.9167\n",
      "-------------------------------------------\n",
      "Epoch:[104/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1357\n",
      "Average Train Loss: 0.0857; Train Acc: 96.5733; Train mean IoU: 0.9657\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1404\n",
      "Average Test Loss: 0.2978; Test Acc: 91.4778; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[105/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0812\n",
      "Average Train Loss: 0.0851; Train Acc: 96.5748; Train mean IoU: 0.9657\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1559\n",
      "Average Test Loss: 0.3013; Test Acc: 91.5996; Test mean IoU: 0.9160\n",
      "-------------------------------------------\n",
      "Epoch:[106/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0912\n",
      "Average Train Loss: 0.0848; Train Acc: 96.5856; Train mean IoU: 0.9659\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1510\n",
      "Average Test Loss: 0.2988; Test Acc: 91.6325; Test mean IoU: 0.9163\n",
      "-------------------------------------------\n",
      "Epoch:[107/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0968\n",
      "Average Train Loss: 0.0835; Train Acc: 96.6366; Train mean IoU: 0.9664\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1550\n",
      "Average Test Loss: 0.3087; Test Acc: 91.0438; Test mean IoU: 0.9104\n",
      "-------------------------------------------\n",
      "Epoch:[108/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1007\n",
      "Average Train Loss: 0.0834; Train Acc: 96.6351; Train mean IoU: 0.9664\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1505\n",
      "Average Test Loss: 0.3028; Test Acc: 91.5792; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[109/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0970\n",
      "Average Train Loss: 0.0829; Train Acc: 96.6597; Train mean IoU: 0.9666\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1618\n",
      "Average Test Loss: 0.3025; Test Acc: 91.4830; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[110/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1105\n",
      "Average Train Loss: 0.0830; Train Acc: 96.6657; Train mean IoU: 0.9667\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1733\n",
      "Average Test Loss: 0.3057; Test Acc: 91.5053; Test mean IoU: 0.9151\n",
      "-------------------------------------------\n",
      "Epoch:[111/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0907\n",
      "Average Train Loss: 0.0840; Train Acc: 96.6121; Train mean IoU: 0.9661\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1343\n",
      "Average Test Loss: 0.3100; Test Acc: 91.5194; Test mean IoU: 0.9152\n",
      "-------------------------------------------\n",
      "Epoch:[112/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0919\n",
      "Average Train Loss: 0.0825; Train Acc: 96.6745; Train mean IoU: 0.9667\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1473\n",
      "Average Test Loss: 0.3151; Test Acc: 91.3120; Test mean IoU: 0.9131\n",
      "-------------------------------------------\n",
      "Epoch:[113/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0969\n",
      "Average Train Loss: 0.0820; Train Acc: 96.6983; Train mean IoU: 0.9670\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1390\n",
      "Average Test Loss: 0.3094; Test Acc: 91.3895; Test mean IoU: 0.9139\n",
      "-------------------------------------------\n",
      "Epoch:[114/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0839\n",
      "Average Train Loss: 0.0824; Train Acc: 96.6597; Train mean IoU: 0.9666\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1562\n",
      "Average Test Loss: 0.3089; Test Acc: 91.2611; Test mean IoU: 0.9126\n",
      "-------------------------------------------\n",
      "Epoch:[115/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1295\n",
      "Average Train Loss: 0.0825; Train Acc: 96.6811; Train mean IoU: 0.9668\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1405\n",
      "Average Test Loss: 0.3083; Test Acc: 91.4439; Test mean IoU: 0.9144\n",
      "-------------------------------------------\n",
      "Epoch:[116/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0868\n",
      "Average Train Loss: 0.0821; Train Acc: 96.6855; Train mean IoU: 0.9669\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1371\n",
      "Average Test Loss: 0.3107; Test Acc: 91.5446; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[117/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1069\n",
      "Average Train Loss: 0.0811; Train Acc: 96.7257; Train mean IoU: 0.9673\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1393\n",
      "Average Test Loss: 0.3110; Test Acc: 91.5848; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[118/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1343\n",
      "Average Train Loss: 0.0819; Train Acc: 96.7090; Train mean IoU: 0.9671\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1664\n",
      "Average Test Loss: 0.3153; Test Acc: 91.4844; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[119/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0956\n",
      "Average Train Loss: 0.0809; Train Acc: 96.7425; Train mean IoU: 0.9674\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1419\n",
      "Average Test Loss: 0.3105; Test Acc: 91.4797; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[120/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0931\n",
      "Average Train Loss: 0.0821; Train Acc: 96.6918; Train mean IoU: 0.9669\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1333\n",
      "Average Test Loss: 0.3179; Test Acc: 91.5211; Test mean IoU: 0.9152\n",
      "-------------------------------------------\n",
      "Epoch:[121/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0984\n",
      "Average Train Loss: 0.0802; Train Acc: 96.7657; Train mean IoU: 0.9677\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1307\n",
      "Average Test Loss: 0.3079; Test Acc: 91.5665; Test mean IoU: 0.9157\n",
      "-------------------------------------------\n",
      "Epoch:[122/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1003\n",
      "Average Train Loss: 0.0795; Train Acc: 96.7946; Train mean IoU: 0.9679\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1343\n",
      "Average Test Loss: 0.3144; Test Acc: 91.5023; Test mean IoU: 0.9150\n",
      "-------------------------------------------\n",
      "Epoch:[123/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0805\n",
      "Average Train Loss: 0.0787; Train Acc: 96.8339; Train mean IoU: 0.9683\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1498\n",
      "Average Test Loss: 0.3112; Test Acc: 91.5471; Test mean IoU: 0.9155\n",
      "-------------------------------------------\n",
      "Epoch:[124/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0850\n",
      "Average Train Loss: 0.0790; Train Acc: 96.8113; Train mean IoU: 0.9681\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1450\n",
      "Average Test Loss: 0.3137; Test Acc: 91.5708; Test mean IoU: 0.9157\n",
      "-------------------------------------------\n",
      "Epoch:[125/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0881\n",
      "Average Train Loss: 0.0795; Train Acc: 96.7980; Train mean IoU: 0.9680\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1375\n",
      "Average Test Loss: 0.3149; Test Acc: 91.4274; Test mean IoU: 0.9143\n",
      "-------------------------------------------\n",
      "Epoch:[126/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0967\n",
      "Average Train Loss: 0.0792; Train Acc: 96.8057; Train mean IoU: 0.9681\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1361\n",
      "Average Test Loss: 0.3109; Test Acc: 91.5400; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[127/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0848\n",
      "Average Train Loss: 0.0775; Train Acc: 96.8803; Train mean IoU: 0.9688\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1566\n",
      "Average Test Loss: 0.3172; Test Acc: 91.4508; Test mean IoU: 0.9145\n",
      "-------------------------------------------\n",
      "Epoch:[128/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1144\n",
      "Average Train Loss: 0.0789; Train Acc: 96.8137; Train mean IoU: 0.9681\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1570\n",
      "Average Test Loss: 0.3136; Test Acc: 91.5785; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[129/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0932\n",
      "Average Train Loss: 0.0786; Train Acc: 96.8378; Train mean IoU: 0.9684\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1473\n",
      "Average Test Loss: 0.3154; Test Acc: 91.5914; Test mean IoU: 0.9159\n",
      "-------------------------------------------\n",
      "Epoch:[130/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0910\n",
      "Average Train Loss: 0.0783; Train Acc: 96.8384; Train mean IoU: 0.9684\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1437\n",
      "Average Test Loss: 0.3126; Test Acc: 91.5646; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[131/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1193\n",
      "Average Train Loss: 0.0782; Train Acc: 96.8594; Train mean IoU: 0.9686\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1552\n",
      "Average Test Loss: 0.3174; Test Acc: 91.4966; Test mean IoU: 0.9150\n",
      "-------------------------------------------\n",
      "Epoch:[132/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0835\n",
      "Average Train Loss: 0.0776; Train Acc: 96.8617; Train mean IoU: 0.9686\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1396\n",
      "Average Test Loss: 0.3151; Test Acc: 91.5553; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[133/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0993\n",
      "Average Train Loss: 0.0780; Train Acc: 96.8603; Train mean IoU: 0.9686\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1417\n",
      "Average Test Loss: 0.3151; Test Acc: 91.5098; Test mean IoU: 0.9151\n",
      "-------------------------------------------\n",
      "Epoch:[134/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1026\n",
      "Average Train Loss: 0.0780; Train Acc: 96.8634; Train mean IoU: 0.9686\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1682\n",
      "Average Test Loss: 0.3175; Test Acc: 91.4833; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[135/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0785\n",
      "Average Train Loss: 0.0769; Train Acc: 96.9067; Train mean IoU: 0.9691\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1638\n",
      "Average Test Loss: 0.3175; Test Acc: 91.4807; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[136/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1033\n",
      "Average Train Loss: 0.0781; Train Acc: 96.8563; Train mean IoU: 0.9686\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1434\n",
      "Average Test Loss: 0.3124; Test Acc: 91.6230; Test mean IoU: 0.9162\n",
      "-------------------------------------------\n",
      "Epoch:[137/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1185\n",
      "Average Train Loss: 0.0780; Train Acc: 96.8716; Train mean IoU: 0.9687\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1379\n",
      "Average Test Loss: 0.3086; Test Acc: 91.5897; Test mean IoU: 0.9159\n",
      "-------------------------------------------\n",
      "Epoch:[138/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0968\n",
      "Average Train Loss: 0.0779; Train Acc: 96.8616; Train mean IoU: 0.9686\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1321\n",
      "Average Test Loss: 0.3139; Test Acc: 91.4322; Test mean IoU: 0.9143\n",
      "-------------------------------------------\n",
      "Epoch:[139/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1073\n",
      "Average Train Loss: 0.0784; Train Acc: 96.8329; Train mean IoU: 0.9683\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1539\n",
      "Average Test Loss: 0.3207; Test Acc: 91.4024; Test mean IoU: 0.9140\n",
      "-------------------------------------------\n",
      "Epoch:[140/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0838\n",
      "Average Train Loss: 0.0776; Train Acc: 96.8673; Train mean IoU: 0.9687\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1212\n",
      "Average Test Loss: 0.3145; Test Acc: 91.5381; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[141/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0810\n",
      "Average Train Loss: 0.0766; Train Acc: 96.9046; Train mean IoU: 0.9690\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1286\n",
      "Average Test Loss: 0.3154; Test Acc: 91.5318; Test mean IoU: 0.9153\n",
      "-------------------------------------------\n",
      "Epoch:[142/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0828\n",
      "Average Train Loss: 0.0764; Train Acc: 96.9189; Train mean IoU: 0.9692\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1235\n",
      "Average Test Loss: 0.3151; Test Acc: 91.5785; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[143/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0831\n",
      "Average Train Loss: 0.0762; Train Acc: 96.9276; Train mean IoU: 0.9693\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1217\n",
      "Average Test Loss: 0.3178; Test Acc: 91.5244; Test mean IoU: 0.9152\n",
      "-------------------------------------------\n",
      "Epoch:[144/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0814\n",
      "Average Train Loss: 0.0760; Train Acc: 96.9291; Train mean IoU: 0.9693\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1287\n",
      "Average Test Loss: 0.3166; Test Acc: 91.5665; Test mean IoU: 0.9157\n",
      "-------------------------------------------\n",
      "Epoch:[145/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0932\n",
      "Average Train Loss: 0.0763; Train Acc: 96.9277; Train mean IoU: 0.9693\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1150\n",
      "Average Test Loss: 0.3162; Test Acc: 91.5824; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[146/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1882\n",
      "Average Train Loss: 0.0779; Train Acc: 96.8867; Train mean IoU: 0.9689\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1355\n",
      "Average Test Loss: 0.3125; Test Acc: 91.5696; Test mean IoU: 0.9157\n",
      "-------------------------------------------\n",
      "Epoch:[147/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0921\n",
      "Average Train Loss: 0.0767; Train Acc: 96.9062; Train mean IoU: 0.9691\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1288\n",
      "Average Test Loss: 0.3162; Test Acc: 91.5822; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[148/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0796\n",
      "Average Train Loss: 0.0752; Train Acc: 96.9689; Train mean IoU: 0.9697\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1380\n",
      "Average Test Loss: 0.3154; Test Acc: 91.5437; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[149/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1000\n",
      "Average Train Loss: 0.0748; Train Acc: 96.9984; Train mean IoU: 0.9700\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1361\n",
      "Average Test Loss: 0.3172; Test Acc: 91.6007; Test mean IoU: 0.9160\n",
      "-------------------------------------------\n",
      "Epoch:[150/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0738\n",
      "Average Train Loss: 0.0753; Train Acc: 96.9587; Train mean IoU: 0.9696\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1312\n",
      "Average Test Loss: 0.3184; Test Acc: 91.6187; Test mean IoU: 0.9162\n",
      "-------------------------------------------\n",
      "Epoch:[151/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1685\n",
      "Average Train Loss: 0.0770; Train Acc: 96.9184; Train mean IoU: 0.9692\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1435\n",
      "Average Test Loss: 0.3168; Test Acc: 91.5943; Test mean IoU: 0.9159\n",
      "-------------------------------------------\n",
      "Epoch:[152/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1111\n",
      "Average Train Loss: 0.0755; Train Acc: 96.9664; Train mean IoU: 0.9697\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1346\n",
      "Average Test Loss: 0.3155; Test Acc: 91.5994; Test mean IoU: 0.9160\n",
      "-------------------------------------------\n",
      "Epoch:[153/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0845\n",
      "Average Train Loss: 0.0752; Train Acc: 96.9716; Train mean IoU: 0.9697\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1341\n",
      "Average Test Loss: 0.3169; Test Acc: 91.6614; Test mean IoU: 0.9166\n",
      "-------------------------------------------\n",
      "Epoch:[154/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0909\n",
      "Average Train Loss: 0.0752; Train Acc: 96.9685; Train mean IoU: 0.9697\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1458\n",
      "Average Test Loss: 0.3200; Test Acc: 91.4829; Test mean IoU: 0.9148\n",
      "-------------------------------------------\n",
      "Epoch:[155/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0974\n",
      "Average Train Loss: 0.0750; Train Acc: 96.9772; Train mean IoU: 0.9698\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1353\n",
      "Average Test Loss: 0.3203; Test Acc: 91.6126; Test mean IoU: 0.9161\n",
      "-------------------------------------------\n",
      "Epoch:[156/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0734\n",
      "Average Train Loss: 0.0752; Train Acc: 96.9607; Train mean IoU: 0.9696\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1392\n",
      "Average Test Loss: 0.3195; Test Acc: 91.5092; Test mean IoU: 0.9151\n",
      "-------------------------------------------\n",
      "Epoch:[157/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0988\n",
      "Average Train Loss: 0.0752; Train Acc: 96.9699; Train mean IoU: 0.9697\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1412\n",
      "Average Test Loss: 0.3214; Test Acc: 91.5005; Test mean IoU: 0.9150\n",
      "-------------------------------------------\n",
      "Epoch:[158/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1953\n",
      "Average Train Loss: 0.0765; Train Acc: 96.9638; Train mean IoU: 0.9696\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1431\n",
      "Average Test Loss: 0.3195; Test Acc: 91.6096; Test mean IoU: 0.9161\n",
      "-------------------------------------------\n",
      "Epoch:[159/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0884\n",
      "Average Train Loss: 0.0748; Train Acc: 96.9816; Train mean IoU: 0.9698\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1373\n",
      "Average Test Loss: 0.3198; Test Acc: 91.6146; Test mean IoU: 0.9161\n",
      "-------------------------------------------\n",
      "Epoch:[160/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0833\n",
      "Average Train Loss: 0.0751; Train Acc: 96.9782; Train mean IoU: 0.9698\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1372\n",
      "Average Test Loss: 0.3203; Test Acc: 91.5815; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[161/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1127\n",
      "Average Train Loss: 0.0753; Train Acc: 96.9782; Train mean IoU: 0.9698\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1498\n",
      "Average Test Loss: 0.3189; Test Acc: 91.5828; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[162/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0862\n",
      "Average Train Loss: 0.0748; Train Acc: 96.9848; Train mean IoU: 0.9698\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1403\n",
      "Average Test Loss: 0.3231; Test Acc: 91.5865; Test mean IoU: 0.9159\n",
      "-------------------------------------------\n",
      "Epoch:[163/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0984\n",
      "Average Train Loss: 0.0743; Train Acc: 97.0128; Train mean IoU: 0.9701\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1497\n",
      "Average Test Loss: 0.3182; Test Acc: 91.5673; Test mean IoU: 0.9157\n",
      "-------------------------------------------\n",
      "Epoch:[164/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1119\n",
      "Average Train Loss: 0.0744; Train Acc: 97.0187; Train mean IoU: 0.9702\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1406\n",
      "Average Test Loss: 0.3166; Test Acc: 91.5436; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[165/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0932\n",
      "Average Train Loss: 0.0749; Train Acc: 96.9858; Train mean IoU: 0.9699\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1475\n",
      "Average Test Loss: 0.3203; Test Acc: 91.5582; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[166/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0912\n",
      "Average Train Loss: 0.0745; Train Acc: 96.9962; Train mean IoU: 0.9700\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1457\n",
      "Average Test Loss: 0.3184; Test Acc: 91.5683; Test mean IoU: 0.9157\n",
      "-------------------------------------------\n",
      "Epoch:[167/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0816\n",
      "Average Train Loss: 0.0747; Train Acc: 96.9947; Train mean IoU: 0.9699\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1449\n",
      "Average Test Loss: 0.3222; Test Acc: 91.5345; Test mean IoU: 0.9153\n",
      "-------------------------------------------\n",
      "Epoch:[168/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0920\n",
      "Average Train Loss: 0.0739; Train Acc: 97.0331; Train mean IoU: 0.9703\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1461\n",
      "Average Test Loss: 0.3248; Test Acc: 91.5403; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[169/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2371\n",
      "Average Train Loss: 0.0759; Train Acc: 97.0034; Train mean IoU: 0.9700\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1687\n",
      "Average Test Loss: 0.3177; Test Acc: 91.6023; Test mean IoU: 0.9160\n",
      "-------------------------------------------\n",
      "Epoch:[170/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1026\n",
      "Average Train Loss: 0.0746; Train Acc: 96.9954; Train mean IoU: 0.9700\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1456\n",
      "Average Test Loss: 0.3241; Test Acc: 91.5608; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[171/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1091\n",
      "Average Train Loss: 0.0748; Train Acc: 97.0043; Train mean IoU: 0.9700\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1441\n",
      "Average Test Loss: 0.3213; Test Acc: 91.5333; Test mean IoU: 0.9153\n",
      "-------------------------------------------\n",
      "Epoch:[172/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1231\n",
      "Average Train Loss: 0.0747; Train Acc: 97.0065; Train mean IoU: 0.9701\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1408\n",
      "Average Test Loss: 0.3195; Test Acc: 91.5769; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[173/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1179\n",
      "Average Train Loss: 0.0752; Train Acc: 96.9763; Train mean IoU: 0.9698\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1569\n",
      "Average Test Loss: 0.3248; Test Acc: 91.5188; Test mean IoU: 0.9152\n",
      "-------------------------------------------\n",
      "Epoch:[174/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0982\n",
      "Average Train Loss: 0.0743; Train Acc: 97.0078; Train mean IoU: 0.9701\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1504\n",
      "Average Test Loss: 0.3184; Test Acc: 91.5504; Test mean IoU: 0.9155\n",
      "-------------------------------------------\n",
      "Epoch:[175/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0746\n",
      "Average Train Loss: 0.0740; Train Acc: 97.0104; Train mean IoU: 0.9701\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1392\n",
      "Average Test Loss: 0.3203; Test Acc: 91.5970; Test mean IoU: 0.9160\n",
      "-------------------------------------------\n",
      "Epoch:[176/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1044\n",
      "Average Train Loss: 0.0741; Train Acc: 97.0124; Train mean IoU: 0.9701\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1316\n",
      "Average Test Loss: 0.3182; Test Acc: 91.5632; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[177/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0890\n",
      "Average Train Loss: 0.0741; Train Acc: 97.0159; Train mean IoU: 0.9702\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1432\n",
      "Average Test Loss: 0.3214; Test Acc: 91.5426; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[178/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.2205\n",
      "Average Train Loss: 0.0762; Train Acc: 96.9801; Train mean IoU: 0.9698\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1457\n",
      "Average Test Loss: 0.3210; Test Acc: 91.5205; Test mean IoU: 0.9152\n",
      "-------------------------------------------\n",
      "Epoch:[179/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0829\n",
      "Average Train Loss: 0.0743; Train Acc: 97.0016; Train mean IoU: 0.9700\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1467\n",
      "Average Test Loss: 0.3212; Test Acc: 91.5632; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[180/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0953\n",
      "Average Train Loss: 0.0743; Train Acc: 97.0094; Train mean IoU: 0.9701\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1448\n",
      "Average Test Loss: 0.3214; Test Acc: 91.5725; Test mean IoU: 0.9157\n",
      "-------------------------------------------\n",
      "Epoch:[181/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1153\n",
      "Average Train Loss: 0.0743; Train Acc: 97.0141; Train mean IoU: 0.9701\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1461\n",
      "Average Test Loss: 0.3202; Test Acc: 91.5572; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[182/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0907\n",
      "Average Train Loss: 0.0737; Train Acc: 97.0419; Train mean IoU: 0.9704\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1479\n",
      "Average Test Loss: 0.3203; Test Acc: 91.5437; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[183/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1090\n",
      "Average Train Loss: 0.0739; Train Acc: 97.0404; Train mean IoU: 0.9704\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1491\n",
      "Average Test Loss: 0.3244; Test Acc: 91.5417; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[184/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0990\n",
      "Average Train Loss: 0.0737; Train Acc: 97.0361; Train mean IoU: 0.9704\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1298\n",
      "Average Test Loss: 0.3189; Test Acc: 91.6449; Test mean IoU: 0.9164\n",
      "-------------------------------------------\n",
      "Epoch:[185/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0936\n",
      "Average Train Loss: 0.0740; Train Acc: 97.0214; Train mean IoU: 0.9702\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1456\n",
      "Average Test Loss: 0.3216; Test Acc: 91.5583; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[186/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0757\n",
      "Average Train Loss: 0.0738; Train Acc: 97.0248; Train mean IoU: 0.9702\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1469\n",
      "Average Test Loss: 0.3230; Test Acc: 91.5512; Test mean IoU: 0.9155\n",
      "-------------------------------------------\n",
      "Epoch:[187/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0852\n",
      "Average Train Loss: 0.0736; Train Acc: 97.0382; Train mean IoU: 0.9704\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1434\n",
      "Average Test Loss: 0.3225; Test Acc: 91.5420; Test mean IoU: 0.9154\n",
      "-------------------------------------------\n",
      "Epoch:[188/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0854\n",
      "Average Train Loss: 0.0737; Train Acc: 97.0400; Train mean IoU: 0.9704\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1394\n",
      "Average Test Loss: 0.3220; Test Acc: 91.5527; Test mean IoU: 0.9155\n",
      "-------------------------------------------\n",
      "Epoch:[189/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0898\n",
      "Average Train Loss: 0.0737; Train Acc: 97.0280; Train mean IoU: 0.9703\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1408\n",
      "Average Test Loss: 0.3202; Test Acc: 91.5751; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n",
      "Epoch:[190/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1011\n",
      "Average Train Loss: 0.0737; Train Acc: 97.0346; Train mean IoU: 0.9703\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1460\n",
      "Average Test Loss: 0.3224; Test Acc: 91.5862; Test mean IoU: 0.9159\n",
      "-------------------------------------------\n",
      "Epoch:[191/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0937\n",
      "Average Train Loss: 0.0734; Train Acc: 97.0445; Train mean IoU: 0.9704\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1413\n",
      "Average Test Loss: 0.3210; Test Acc: 91.5566; Test mean IoU: 0.9156\n",
      "-------------------------------------------\n",
      "Epoch:[192/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1125\n",
      "Average Train Loss: 0.0736; Train Acc: 97.0498; Train mean IoU: 0.9705\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1456\n",
      "Average Test Loss: 0.3224; Test Acc: 91.5195; Test mean IoU: 0.9152\n",
      "-------------------------------------------\n",
      "Epoch:[193/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1406\n",
      "Average Train Loss: 0.0745; Train Acc: 97.0134; Train mean IoU: 0.9701\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1418\n",
      "Average Test Loss: 0.3188; Test Acc: 91.6067; Test mean IoU: 0.9161\n",
      "-------------------------------------------\n",
      "Epoch:[194/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0850\n",
      "Average Train Loss: 0.0733; Train Acc: 97.0522; Train mean IoU: 0.9705\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1354\n",
      "Average Test Loss: 0.3186; Test Acc: 91.5934; Test mean IoU: 0.9159\n",
      "-------------------------------------------\n",
      "Epoch:[195/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0975\n",
      "Average Train Loss: 0.0731; Train Acc: 97.0608; Train mean IoU: 0.9706\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1361\n",
      "Average Test Loss: 0.3219; Test Acc: 91.5543; Test mean IoU: 0.9155\n",
      "-------------------------------------------\n",
      "Epoch:[196/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0934\n",
      "Average Train Loss: 0.0736; Train Acc: 97.0441; Train mean IoU: 0.9704\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1463\n",
      "Average Test Loss: 0.3231; Test Acc: 91.5543; Test mean IoU: 0.9155\n",
      "-------------------------------------------\n",
      "Epoch:[197/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0955\n",
      "Average Train Loss: 0.0741; Train Acc: 97.0174; Train mean IoU: 0.9702\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1490\n",
      "Average Test Loss: 0.3197; Test Acc: 91.5185; Test mean IoU: 0.9152\n",
      "-------------------------------------------\n",
      "Epoch:[198/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.1000\n",
      "Average Train Loss: 0.0729; Train Acc: 97.0678; Train mean IoU: 0.9707\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1400\n",
      "Average Test Loss: 0.3180; Test Acc: 91.6240; Test mean IoU: 0.9162\n",
      "-------------------------------------------\n",
      "Epoch:[199/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0814\n",
      "Average Train Loss: 0.0736; Train Acc: 97.0275; Train mean IoU: 0.9703\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1388\n",
      "Average Test Loss: 0.3223; Test Acc: 91.5924; Test mean IoU: 0.9159\n",
      "-------------------------------------------\n",
      "Epoch:[200/200]\n",
      "Training...\n",
      "Iter: [074/074] Loss: 0.0874\n",
      "Average Train Loss: 0.0738; Train Acc: 97.0321; Train mean IoU: 0.9703\n",
      "\n",
      "Testing...\n",
      "Iter: [341/341] Loss: 0.1497\n",
      "Average Test Loss: 0.3186; Test Acc: 91.5768; Test mean IoU: 0.9158\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "network = Segmentation(train_seg_dataset.num_classes, alignment=True).cuda()\n",
    "epochs = 200 # you can change the value to a small number for debugging\n",
    "\n",
    "## TASK 2.13\n",
    "# see Appendix C\n",
    "# choose an optimizer and an initial learning rate\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08,\n",
    "            weight_decay=1e-4)\n",
    "# choose a lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "#######3\n",
    "\n",
    "train_seg(train_seg_loader, test_seg_loader, network, optimizer, epochs, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the best test mIoU you can get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best test mIoU obtained from the training is 0.9166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37tch13",
   "language": "python",
   "name": "py37tch12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
